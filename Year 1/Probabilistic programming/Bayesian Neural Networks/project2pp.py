# -*- coding: utf-8 -*-
"""Project2PP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vdBkxnoDzVwS2UV4MSst2mMQEBVvnz7l

# **Bayesian Neural Networks**

# **Utils**
Some utility function to visualize the dataset and the model's predictions
"""

from google.colab import files, auth, drive

# Mount to drive
drive.mount('/content/gdrive', force_remount=True)
data_dir_drive ='/content/gdrive/My Drive/Colab Notebooks/PP/Project2/'

# Unzip dataset to /content
import time

start = time.time()

!unzip -u '/content/gdrive/My Drive/Colab Notebooks/PP/Project2/emg-4.zip' -d '/content/gdrive/My Drive/Colab Notebooks/PP/Project2/'

print('Took', (time.time() - start), ' secundes to unzip')

! ls '/content/gdrive/My Drive/Colab Notebooks/PML/Proj1/'

!pip install pymc

! pip install edward

! pip install tensorflow==1.2

import itertools
import matplotlib.pyplot as plt

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

"""# **Artificial Dataset**"""

from sklearn.preprocessing import scale
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

X = np.random.randn(100, 2)
Y = np.tanh(X[:, 0] + X[:, 1])
Y = 1. / (1. + np.exp(-(Y + Y)))
Y = Y > 0.5

X = scale(X)
X = X.astype(float)
Y = Y.astype(float)

fig, ax = plt.subplots()
ax.scatter(X[Y==0, 0], X[Y==0, 1], label='Class 0')
ax.scatter(X[Y==1, 0], X[Y==1, 1], color='r', label='Class 1')
sns.despine(); ax.legend()
ax.set(xlabel='X', ylabel='Y', title='Toy binary classification data set');

"""## **Bayesian Neural Networks**"""

N = 800
X = np.repeat(X, 10, axis = 0)
Y = np.repeat(Y, 10, axis = 0)
train_data, test_data = X[:N], X[N:]
train_labels, test_labels = Y[:N], Y[N:]

in_size = train_data.shape[1]
hidden_size = 2
out_size = 2

EPOCH_NUM = 10
BATCH_SIZE = 100

import edward as ed
from edward.models import Normal, Categorical, Bernoulli
import tensorflow as tf

data_placeholder = tf.placeholder(tf.float32, shape=(None, in_size)) # a variable that we will assign data to at a later date
label_placeholder = tf.placeholder(tf.int32, shape=(BATCH_SIZE)) # a variable that we will assign data to at a later date

w1 = Normal(loc=tf.zeros([in_size, hidden_size]), scale=tf.ones([in_size, hidden_size]))
w2 = Normal(loc=tf.zeros([hidden_size, out_size]), scale=tf.ones([hidden_size, out_size]))
b1 = Normal(loc=tf.zeros([hidden_size]), scale=tf.ones([hidden_size]))
b2 = Normal(loc=tf.zeros([out_size]), scale=tf.ones([out_size]))

# activation functions
act_1 = tf.nn.tanh(tf.matmul(data_placeholder, w1) + b1)
act_out = tf.nn.sigmoid(tf.matmul(act_1,w2) + b2)

out_pre = Categorical(act_out)

# latent variables
qw1 = Normal(loc=tf.Variable(tf.random_normal([in_size, hidden_size])), scale=tf.Variable(tf.random_normal([in_size, hidden_size])))
qw2 = Normal(loc=tf.Variable(tf.random_normal([hidden_size, out_size])), scale=tf.Variable(tf.random_normal([hidden_size, out_size])))
qb1 = Normal(loc=tf.Variable(tf.random_normal([hidden_size])), scale=tf.Variable(tf.random_normal([hidden_size])))
qb2 = Normal(loc=tf.Variable(tf.random_normal([out_size])), scale=tf.Variable(tf.random_normal([out_size])))

out = Categorical(tf.nn.sigmoid(tf.matmul(tf.nn.tanh(tf.matmul(data_placeholder, qw1) + qb1), qw2) + qb2))

# Variational inference with the KL divergence
# This class minimizes the objective by automatically selecting from a variety of black box inference techniques.
inference = ed.KLqp({w1: qw1, w2: qw2, b1: qb1, b2: qb2}, data={out_pre: label_placeholder})
inference.initialize()

# open a tensorflow  Session 
sess = tf.Session()
sess.run(tf.global_variables_initializer())

# to plot accuracy
t, v = [], []

with sess:
    samples_num = 1000
    for epoch in range(EPOCH_NUM):
        # batch generator
        perm = np.random.permutation(N)
        for i in range(0, N, BATCH_SIZE):
            batch_data = train_data[perm[i:i+BATCH_SIZE]]
            batch_labels = train_labels[perm[i:i+BATCH_SIZE]]
            # runs the graph once to update TensorFlow variables in the graph, which is called in a loop until convergence;
            inference.update(feed_dict={data_placeholder: batch_data, label_placeholder: batch_labels})

        # generate samples_num samples to evaluate the model on train set
        labels_samples = out.sample(samples_num).eval(feed_dict={data_placeholder: train_data})
        acc = (np.round(labels_samples.sum(axis=0) / samples_num) == train_labels).mean()
        t.append(acc)
        # generate samples_num samples to evaluate the model on test set
        labels_samples = out.sample(samples_num).eval(feed_dict={data_placeholder: test_data})
        test_acc = (np.round(labels_samples.sum(axis=0) / samples_num) == test_labels).mean()
        v.append(test_acc)
        print('epoch:\t'+ str(epoch+1) + '\taccuracy:\t' + str(acc) + '\tvaridation accuracy:\t' + str(test_acc))

    # make samples for posterior of weights
    qw1_samples = qw1.sample(samples_num).eval(feed_dict={})
    qw2_samples = qw2.sample(samples_num).eval(feed_dict={})
    qb1_samples = qb1.sample(samples_num).eval(feed_dict={})
    qb2_samples = qb2.sample(samples_num).eval(feed_dict={})
    print('accuracy = ' + str(test_acc * 100) + '%')

e = range(1, EPOCH_NUM+1)
plt.plot(e, t, '-b', e, v, '-r')
plt.show()

plt.hist(qw1_samples[:, 0, 0])
plt.title('Posterior of w11')
plt.show()

plt.hist(qw1_samples[:, 0, 1])
plt.title('Posterior of w12')
plt.show()

plt.hist(qw1_samples[:, 1, 0])
plt.title('Posterior of w21')
plt.show()

plt.hist(qw1_samples[:, 1, 1])
plt.title('Posterior of w22')
plt.show()

plt.hist(qw2_samples[:, 0, 0])
plt.title('Posterior of w31')
plt.show()

plt.hist(qb1_samples[:, 0])
plt.title('Posterior of b1')
plt.show()

plt.hist(qb1_samples[:, 1])
plt.title('Posterior of b2')
plt.show()

plt.hist(qb2_samples[:, 0])
plt.title('Posterior of b31')
plt.show()

plt.hist(qb2_samples[:, 1])
plt.title('Posterior of b32')
plt.show()

"""## **“Classic” Neural Network (MLP)**"""

# shuffle data
randPerm = np.random.permutation((X.shape)[0])
pureDataRand = X[randPerm][:]
LabelsRand = Y[randPerm][:]

import math

train_size = math.floor(0.8 * (pureDataRand.shape)[0])
test_size = (pureDataRand.shape)[0] - train_size
train_data = pureDataRand[0:train_size][:]
train_labels = LabelsRand[0:train_size][:]
test_data = pureDataRand[train_size:][:]
test_labels = LabelsRand[train_size:][:]
print(train_size)
print(test_size)
print(train_data.shape)
print(train_labels.shape)
print(test_data.shape)
print(test_labels.shape)

from sklearn import preprocessing # import the preprocessing library
 
# define the normalizer
scaler = preprocessing.StandardScaler()
# compute the mean and the std on the training set
scaler.fit(train_data)

# print the mean
print('mean =', scaler.mean_.shape)  
# print the standard deviation
print('std =', scaler.scale_.shape) 

# scaling the training data
train_data_scaled = scaler.transform(train_data)
print(train_data_scaled.shape)  

# scaling the test data
test_data_scaled = scaler.transform(test_data)
print(test_data_scaled.shape)

import torch

# using CUDA (GPU) if is possible
CUDA_LAUNCH_BLOCKING=1

plt.ion()  

if torch.cuda.is_available():
    device = torch.device('cuda')
    print("Using CUDA")
else:
    device = torch.device('cpu')
    print("Using CPU")

# transform all fata to tensors and move to GPU
train_data_scaled_tensor = torch.Tensor(train_data_scaled).to(device)
train_labels_tensor = torch.Tensor(train_labels).to(device)
test_data_scaled_tensor = torch.Tensor(test_data_scaled).to(device)
test_labels_tensor = torch.Tensor(test_labels).to(device)

import matplotlib.pyplot as plt

# plot loss function
def plot_loss(loss, label, color='blue'):
    plt.plot(loss, label=label, color=color)
    plt.legend()

import torch.nn as nn
import torch.nn.functional as F

class Net(nn.Module):
    # nn.Module - base class for all models
    # easy acces to .parameters() and .zero_grad()
    # define .forward() instead of __call__()
    
    def __init__(self, in_size, h_size1, out_size):
        super().__init__()
        self._layer1 = nn.Linear(in_size,h_size1).to(device)
        
    def forward(self, x):
        x = F.tanh(self._layer1(x)).to(device)
        x = F.softmax(x).to(device)
        return x.to(device)
        
    def train(self, train_data, train_labels, 
              epochs=400, lr=0.01, verbose=100, l2_weight=0,
              val_data=None, val_labels=None, plot_val = True):
        #use optimizers to take care of the update step
        optimizer1 = torch.optim.SGD(self.parameters(), lr=lr,
                               weight_decay = l2_weight)
        optimizer2 = torch.optim.Adagrad(self.parameters(), lr=lr,
                               weight_decay = l2_weight)
        optimizer3 = torch.optim.RMSprop(self.parameters(), lr=lr,
                               weight_decay = l2_weight)
        optimizer4 = torch.optim.Adam(self.parameters(), lr=lr,
                               weight_decay = l2_weight)
        
        criterion = nn.CrossEntropyLoss();
        
        train_loss = []
        val_loss = []
        for e in range(epochs):
            optimizer1.zero_grad()   # zero the gradient buffers
            input = train_data
            output = self(train_data)
            loss = criterion(output, train_labels)
            loss.backward()
            optimizer1.step()    # Does the update
            
            train_loss.append(loss.cpu().detach().numpy())
            if verbose!=0 and e%verbose==0:
                print("Loss - train :")
                print(loss)
            if val_data is not None:
                output = self(val_data)
                loss = criterion(output, val_labels)
                if verbose!=0 and e%verbose==0:
                    print("Loss - validation :")
                    print(loss)
                val_loss.append(loss.cpu().detach().numpy())

        if(plot_val):    
            plot_loss(train_loss, 'train-loss')
            if len(val_loss)>0:
                plot_loss(val_loss, 'val-loss', color='red')

    def accuracy(self, data, true_labers):
        num_ok = 0
        for idx, test in enumerate(data):
            output = net(test.type(torch.float))
            target = true_labers[idx]
            if output.max(0)[1] == target:
                num_ok += 1
        return num_ok / len(data)

#define net
net = Net(2,2,2)
net.to(device)
print(net)

#train from all examples from train set
net.train((train_data_scaled_tensor).type(torch.float), (train_labels_tensor).type(torch.long), 
        epochs=1000,lr=0.1,verbose=100)

# evaluate one example from test set
input = test_data_scaled_tensor[0][:]
print(input)
output = net(input.type(torch.float))
print(output)
print(output.max(0)[1])
target = test_labels_tensor[0]
print(target)

# evaluate net from all examples from test set
num_ok = 0
C = np.zeros([2, 2])

for idx, test in enumerate(test_data_scaled_tensor):
    output = net(test.type(torch.float))
    target = test_labels_tensor[idx]
    C[int(test_labels_tensor[idx])][int(output.max(0)[1])] += 1
    if output.max(0)[1] == target:
        num_ok += 1

print('acc = ' + str(num_ok / len(test_data_scaled_tensor)))

print(C)

# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(C, classes=range(2), title='Confusion matrix, without normalization')

# Plot normalized confusion matrix
plt.figure()
plot_confusion_matrix(C, classes=range(2), normalize=True,
                      title='Normalized confusion matrix')

plt.show()

"""# **Iris Dataset - Multiclass**"""

from sklearn import datasets

# import some data to play with
iris = datasets.load_iris()
X = iris.data[:, :3]  # we only take the first two features.
Y = iris.target

X = scale(X)
Y = np.array(Y)
X = X.astype(float)
Y = Y.astype(float)

X.shape

fig, ax = plt.subplots()
ax.scatter(X[Y==0, 0], X[Y==0, 1], label='Class 0')
ax.scatter(X[Y==1, 0], X[Y==1, 1], color='r', label='Class 1')
ax.scatter(X[Y==2, 0], X[Y==2, 1], color='y', label='Class 2')
sns.despine(); ax.legend()
ax.set(xlabel='X', ylabel='Y', title='Toy binary classification data set');

"""## **Bayesian Neural Networks**"""

N = 130
train_data, test_data = X[:N], X[N:]
train_labels, test_labels = Y[:N], Y[N:]

train_data = np.repeat(train_data, 1000, axis = 0)
train_labels = np.repeat(train_labels, 1000, axis = 0)

in_size = train_data.shape[1]
hidden_size = 7
out_size = 3

EPOCH_NUM = 10
BATCH_SIZE = 130

import edward as ed
from edward.models import Normal, Categorical, Bernoulli
import tensorflow as tf

data_placeholder = tf.placeholder(tf.float32, shape=(None, in_size))
label_placeholder = tf.placeholder(tf.int32, shape=(BATCH_SIZE))

w1 = Normal(loc=tf.zeros([in_size, hidden_size]), scale=tf.ones([in_size, hidden_size]))
w2 = Normal(loc=tf.zeros([hidden_size, out_size]), scale=tf.ones([hidden_size, out_size]))
b1 = Normal(loc=tf.zeros([hidden_size]), scale=tf.ones([hidden_size]))
b2 = Normal(loc=tf.zeros([out_size]), scale=tf.ones([out_size]))

# activation functions
act_1 = tf.nn.tanh(tf.matmul(data_placeholder, w1) + b1)
act_out = tf.nn.softmax(tf.matmul(act_1,w2) + b2)

out_pre = Categorical(act_out)

# latent variables
qw1 = Normal(loc=tf.Variable(tf.random_normal([in_size, hidden_size])), scale=tf.Variable(tf.random_normal([in_size, hidden_size])))
qw2 = Normal(loc=tf.Variable(tf.random_normal([hidden_size, out_size])), scale=tf.Variable(tf.random_normal([hidden_size, out_size])))
qb1 = Normal(loc=tf.Variable(tf.random_normal([hidden_size])), scale=tf.Variable(tf.random_normal([hidden_size])))
qb2 = Normal(loc=tf.Variable(tf.random_normal([out_size])), scale=tf.Variable(tf.random_normal([out_size])))

out = Categorical(tf.nn.softmax(tf.matmul(tf.nn.tanh(tf.matmul(data_placeholder, qw1) + qb1), qw2) + qb2))

# Variational inference with the KL divergence
# This class minimizes the objective by automatically selecting from a variety of black box inference techniques.
inference = ed.KLqp({w1: qw1, w2: qw2, b1: qb1, b2: qb2}, data={out_pre: label_placeholder})
inference.initialize()

# open a tensorflow  Session 
sess = tf.Session()
sess.run(tf.global_variables_initializer())

# to plot accuracy
t, v = [], []

with sess:
    samples_num = 1000
    for epoch in range(EPOCH_NUM):
        # batches generator
        perm = np.random.permutation(N)
        for i in range(0, N, BATCH_SIZE):
            batch_data = train_data[perm[i:i+BATCH_SIZE]]
            batch_labels = train_labels[perm[i:i+BATCH_SIZE]]
            # runs the graph once to update TensorFlow variables in the graph, which is called in a loop until convergence;
            inference.update(feed_dict={data_placeholder: batch_data, label_placeholder: batch_labels})

        # generate samples_num samples to evaluate the model on train set    
        labels_samples = out.sample(samples_num).eval(feed_dict={data_placeholder: train_data})
        accs = []
        for lb in labels_samples:
            accs.append((lb == train_labels).mean())
        acc = np.array(accs).mean()
        t.append(acc)

        # generate samples_num samples to evaluate the model on test set
        labels_samples = out.sample(samples_num).eval(feed_dict={data_placeholder: test_data})
        accs = []
        for lb in labels_samples:
            accs.append((lb == test_labels).mean())
        test_acc = np.array(accs).mean()
        v.append(test_acc)
        print('epoch:\t'+ str(epoch+1) + '\taccuracy:\t' + str(acc) + '\tvaridation accuracy:\t' + str(test_acc))

    # make samples for posterior of weights
    qw1_samples = qw1.sample(samples_num).eval(feed_dict={})
    qw2_samples = qw2.sample(samples_num).eval(feed_dict={})
    qb1_samples = qb1.sample(samples_num).eval(feed_dict={})
    qb2_samples = qb2.sample(samples_num).eval(feed_dict={})
    print('accuracy = ' + str(test_acc * 100) + '%')

e = range(1, EPOCH_NUM+1)
plt.plot(e, t, '-b', e, v, '-r')
plt.show()

plt.hist(qw1_samples[:, 0, 0])
plt.title('Posterior of w11')
plt.show()

plt.hist(qw1_samples[:, 0, 1])
plt.title('Posterior of w12')
plt.show()

plt.hist(qw1_samples[:, 1, 0])
plt.title('Posterior of w21')
plt.show()

plt.hist(qw1_samples[:, 1, 1])
plt.title('Posterior of w22')
plt.show()

plt.hist(qw2_samples[:, 0, 0])
plt.title('Posterior of w31')
plt.show()

plt.hist(qb1_samples[:, 0])
plt.title('Posterior of b1')
plt.show()

plt.hist(qb1_samples[:, 1])
plt.title('Posterior of b2')
plt.show()

plt.hist(qb2_samples[:, 0])
plt.title('Posterior of b31')
plt.show()

plt.hist(qb2_samples[:, 1])
plt.title('Posterior of b32')
plt.show()

"""## **“Classic” Neural Network (MLP)**"""

iris = datasets.load_iris()
X = iris.data[:, :3]  # we only take the first two features.
Y = iris.target

# shuffle data
randPerm = np.random.permutation((X.shape)[0])
pureDataRand = X[randPerm][:]
LabelsRand = Y[randPerm][:]

import math

train_size = 130
test_size = (pureDataRand.shape)[0] - train_size
train_data = pureDataRand[0:train_size][:]
train_labels = LabelsRand[0:train_size][:]
test_data = pureDataRand[train_size:][:]
test_labels = LabelsRand[train_size:][:]
print(train_size)
print(test_size)
print(train_data.shape)
print(train_labels.shape)
print(test_data.shape)
print(test_labels.shape)

from sklearn import preprocessing # import the preprocessing library
 
# define the normalizer
scaler = preprocessing.StandardScaler()
# compute the mean and the std on the training set
scaler.fit(train_data)

# print the mean
print('mean =', scaler.mean_.shape)  
# print the standard deviation
print('std =', scaler.scale_.shape) 

# scaling the training data
train_data_scaled = scaler.transform(train_data)
print(train_data_scaled.shape)  

# scaling the test data
test_data_scaled = scaler.transform(test_data)
print(test_data_scaled.shape)

import torch

# using CUDA (GPU) if is possible
CUDA_LAUNCH_BLOCKING=1

plt.ion()  

if torch.cuda.is_available():
    device = torch.device('cuda')
    print("Using CUDA")
else:
    device = torch.device('cpu')
    print("Using CPU")

# transform all fata to tensors and move to GPU
train_data_scaled_tensor = torch.Tensor(train_data_scaled).to(device)
train_labels_tensor = torch.Tensor(train_labels).to(device)
test_data_scaled_tensor = torch.Tensor(test_data_scaled).to(device)
test_labels_tensor = torch.Tensor(test_labels).to(device)

import matplotlib.pyplot as plt

# plot loss function
def plot_loss(loss, label, color='blue'):
    plt.plot(loss, label=label, color=color)
    plt.legend()

import torch.nn as nn
import torch.nn.functional as F

class Net(nn.Module):
    # nn.Module - base class for all models
    # easy acces to .parameters() and .zero_grad()
    # define .forward() instead of __call__()
    
    def __init__(self, in_size, h_size1, out_size):
        super().__init__()
        self._layer1 = nn.Linear(in_size,h_size1).to(device)
        
    def forward(self, x):
        x = F.tanh(self._layer1(x)).to(device)
        x = F.softmax(x).to(device)
        return x.to(device)
        
    def train(self, train_data, train_labels, 
              epochs=400, lr=0.01, verbose=100, l2_weight=0,
              val_data=None, val_labels=None, plot_val = True):
        #use optimizers to take care of the update step
        optimizer1 = torch.optim.SGD(self.parameters(), lr=lr,
                               weight_decay = l2_weight)
        optimizer2 = torch.optim.Adagrad(self.parameters(), lr=lr,
                               weight_decay = l2_weight)
        optimizer3 = torch.optim.RMSprop(self.parameters(), lr=lr,
                               weight_decay = l2_weight)
        optimizer4 = torch.optim.Adam(self.parameters(), lr=lr,
                               weight_decay = l2_weight)
        
        criterion = nn.CrossEntropyLoss();
        
        train_loss = []
        val_loss = []
        for e in range(epochs):
            optimizer1.zero_grad()   # zero the gradient buffers
            input = train_data
            output = self(train_data)
            loss = criterion(output, train_labels)
            loss.backward()
            optimizer1.step()    # Does the update
            
            train_loss.append(loss.cpu().detach().numpy())
            if verbose!=0 and e%verbose==0:
                print("Loss - train :")
                print(loss)
            if val_data is not None:
                output = self(val_data)
                loss = criterion(output, val_labels)
                if verbose!=0 and e%verbose==0:
                    print("Loss - validation :")
                    print(loss)
                val_loss.append(loss.cpu().detach().numpy())

        if(plot_val):    
            plot_loss(train_loss, 'train-loss')
            if len(val_loss)>0:
                plot_loss(val_loss, 'val-loss', color='red')

    def accuracy(self, data, true_labers):
        num_ok = 0
        for idx, test in enumerate(data):
            output = net(test.type(torch.float))
            target = true_labers[idx]
            if output.max(0)[1] == target:
                num_ok += 1
        return num_ok / len(data)

#define net
net = Net(3,7,3)
net.to(device)
print(net)

#train from all examples from train set
net.train((train_data_scaled_tensor).type(torch.float), (train_labels_tensor).type(torch.long), 
        epochs=1000,lr=0.1,verbose=100)

# evaluate one example from test set
input = test_data_scaled_tensor[0][:]
print(input)
output = net(input.type(torch.float))
print(output)
print(output.max(0)[1])
target = test_labels_tensor[0]
print(target)

# evaluate net from all examples from test set
num_ok = 0
C = np.zeros([3, 3])

for idx, test in enumerate(test_data_scaled_tensor):
    output = net(test.type(torch.float))
    target = test_labels_tensor[idx]
    C[int(test_labels_tensor[idx])][int(output.max(0)[1])] += 1
    if output.max(0)[1] == target:
        num_ok += 1

print('acc = ' + str(num_ok / len(test_data_scaled_tensor)))

print(C)

# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(C, classes=range(2), title='Confusion matrix, without normalization')

# Plot normalized confusion matrix
plt.figure()
plot_confusion_matrix(C, classes=range(2), normalize=True,
                      title='Normalized confusion matrix')

plt.show()

"""# **Moons Dataset**"""

from sklearn import datasets
from sklearn.preprocessing import scale
from sklearn.datasets import make_moons
import matplotlib.pyplot as plt
import seaborn as sns

X, Y = make_moons(noise=0.2, random_state=0, n_samples=1000)
X = scale(X)
X = X.astype(float)
Y = Y.astype(float)

fig, ax = plt.subplots()
ax.scatter(X[Y==0, 0], X[Y==0, 1], label='Class 0')
ax.scatter(X[Y==1, 0], X[Y==1, 1], color='r', label='Class 1')
sns.despine(); ax.legend()
ax.set(xlabel='X', ylabel='Y', title='Toy binary classification data set');

"""## **Bayesian Neural Networks**"""

N = 800
train_data, test_data = X[:N], X[N:]
train_labels, test_labels = Y[:N], Y[N:]

in_size = train_data.shape[1]
hidden_size = 2
out_size = 2

EPOCH_NUM = 10
BATCH_SIZE = 100

import edward as ed
from edward.models import Normal, Categorical, Bernoulli
import tensorflow as tf

data_placeholder = tf.placeholder(tf.float32, shape=(None, in_size))
label_placeholder = tf.placeholder(tf.int32, shape=(BATCH_SIZE))

w1 = Normal(loc=tf.zeros([in_size, hidden_size]), scale=tf.ones([in_size, hidden_size]))
w2 = Normal(loc=tf.zeros([hidden_size, out_size]), scale=tf.ones([hidden_size, out_size]))
b1 = Normal(loc=tf.zeros([hidden_size]), scale=tf.ones([hidden_size]))
b2 = Normal(loc=tf.zeros([out_size]), scale=tf.ones([out_size]))

act_1 = tf.nn.tanh(tf.matmul(data_placeholder, w1) + b1)
act_out = tf.nn.softmax(tf.matmul(act_1,w2) + b2)

out_pre = Categorical(act_out)

qw1 = Normal(loc=tf.Variable(tf.random_normal([in_size, hidden_size])), scale=tf.Variable(tf.random_normal([in_size, hidden_size])))
qw2 = Normal(loc=tf.Variable(tf.random_normal([hidden_size, out_size])), scale=tf.Variable(tf.random_normal([hidden_size, out_size])))
qb1 = Normal(loc=tf.Variable(tf.random_normal([hidden_size])), scale=tf.Variable(tf.random_normal([hidden_size])))
qb2 = Normal(loc=tf.Variable(tf.random_normal([out_size])), scale=tf.Variable(tf.random_normal([out_size])))

out = Categorical(tf.nn.softmax(tf.matmul(tf.nn.tanh(tf.matmul(data_placeholder, qw1) + qb1), qw2) + qb2))

inference = ed.KLqp({w1: qw1, w2: qw2, b1: qb1, b2: qb2}, data={out_pre: label_placeholder})
inference.initialize()

sess = tf.Session()
sess.run(tf.global_variables_initializer())

t, v = [], []

with sess:
    samples_num = 1000
    for epoch in range(EPOCH_NUM):
        perm = np.random.permutation(N)
        for i in range(0, N, BATCH_SIZE):
            batch_data = train_data[perm[i:i+BATCH_SIZE]]
            batch_labels = train_labels[perm[i:i+BATCH_SIZE]]
            inference.update(feed_dict={data_placeholder: batch_data, label_placeholder: batch_labels})
        labels_samples = out.sample(samples_num).eval(feed_dict={data_placeholder: train_data})
        acc = (np.round(labels_samples.sum(axis=0) / samples_num) == train_labels).mean()
        t.append(acc)
        labels_samples = out.sample(samples_num).eval(feed_dict={data_placeholder: test_data})
        test_acc = (np.round(labels_samples.sum(axis=0) / samples_num) == test_labels).mean()
        v.append(test_acc)
        print('epoch:\t'+ str(epoch+1) + '\taccuracy:\t' + str(acc) + '\tvaridation accuracy:\t' + str(test_acc))
    qw1_samples = qw1.sample(samples_num).eval(feed_dict={})
    qw2_samples = qw2.sample(samples_num).eval(feed_dict={})
    qb1_samples = qb1.sample(samples_num).eval(feed_dict={})
    qb2_samples = qb2.sample(samples_num).eval(feed_dict={})
    print('accuracy = ' + str(test_acc * 100) + '%')

e = range(1, EPOCH_NUM+1)
plt.plot(e, t, '-b', e, v, '-r')
plt.show()

plt.hist(qw1_samples[:, 0, 0])
plt.title('Posterior of w11')
plt.show()

plt.hist(qw1_samples[:, 0, 1])
plt.title('Posterior of w12')
plt.show()

plt.hist(qw1_samples[:, 1, 0])
plt.title('Posterior of w21')
plt.show()

plt.hist(qw1_samples[:, 1, 1])
plt.title('Posterior of w22')
plt.show()

plt.hist(qw2_samples[:, 0, 0])
plt.title('Posterior of w31')
plt.show()

plt.hist(qb1_samples[:, 0])
plt.title('Posterior of b1')
plt.show()

plt.hist(qb1_samples[:, 1])
plt.title('Posterior of b2')
plt.show()

plt.hist(qb2_samples[:, 0])
plt.title('Posterior of b31')
plt.show()

plt.hist(qb2_samples[:, 1])
plt.title('Posterior of b32')
plt.show()

"""## **“Classic” Neural Network (MLP)**"""

# shuffle data
randPerm = np.random.permutation((X.shape)[0])
pureDataRand = X[randPerm][:]
LabelsRand = Y[randPerm][:]

import math

train_size = math.floor(0.8 * (pureDataRand.shape)[0])
test_size = (pureDataRand.shape)[0] - train_size
train_data = pureDataRand[0:train_size][:]
train_labels = LabelsRand[0:train_size][:]
test_data = pureDataRand[train_size:][:]
test_labels = LabelsRand[train_size:][:]
print(train_size)
print(test_size)
print(train_data.shape)
print(train_labels.shape)
print(test_data.shape)
print(test_labels.shape)

from sklearn import preprocessing # import the preprocessing library
 
# define the normalizer
scaler = preprocessing.StandardScaler()
# compute the mean and the std on the training set
scaler.fit(train_data)

# print the mean
print('mean =', scaler.mean_.shape)  
# print the standard deviation
print('std =', scaler.scale_.shape) 

# scaling the training data
train_data_scaled = scaler.transform(train_data)
print(train_data_scaled.shape)  

# scaling the test data
test_data_scaled = scaler.transform(test_data)
print(test_data_scaled.shape)

import torch

# using CUDA (GPU) if is possible
CUDA_LAUNCH_BLOCKING=1

plt.ion()  

if torch.cuda.is_available():
    device = torch.device('cuda')
    print("Using CUDA")
else:
    device = torch.device('cpu')
    print("Using CPU")

# transform all fata to tensors and move to GPU
train_data_scaled_tensor = torch.Tensor(train_data_scaled).to(device)
train_labels_tensor = torch.Tensor(train_labels).to(device)
test_data_scaled_tensor = torch.Tensor(test_data_scaled).to(device)
test_labels_tensor = torch.Tensor(test_labels).to(device)

import matplotlib.pyplot as plt

# plot loss function
def plot_loss(loss, label, color='blue'):
    plt.plot(loss, label=label, color=color)
    plt.legend()

import torch.nn as nn
import torch.nn.functional as F

class Net(nn.Module):
    # nn.Module - base class for all models
    # easy acces to .parameters() and .zero_grad()
    # define .forward() instead of __call__()
    
    def __init__(self, in_size, h_size1, out_size):
        super().__init__()
        self._layer1 = nn.Linear(in_size,h_size1).to(device)
        
    def forward(self, x):
        x = F.tanh(self._layer1(x)).to(device)
        x = F.softmax(x).to(device)
        return x.to(device)
        
    def train(self, train_data, train_labels, 
              epochs=400, lr=0.01, verbose=100, l2_weight=0,
              val_data=None, val_labels=None, plot_val = True):
        #use optimizers to take care of the update step
        optimizer1 = torch.optim.SGD(self.parameters(), lr=lr,
                               weight_decay = l2_weight)
        optimizer2 = torch.optim.Adagrad(self.parameters(), lr=lr,
                               weight_decay = l2_weight)
        optimizer3 = torch.optim.RMSprop(self.parameters(), lr=lr,
                               weight_decay = l2_weight)
        optimizer4 = torch.optim.Adam(self.parameters(), lr=lr,
                               weight_decay = l2_weight)
        
        criterion = nn.CrossEntropyLoss();
        
        train_loss = []
        val_loss = []
        for e in range(epochs):
            optimizer1.zero_grad()   # zero the gradient buffers
            input = train_data
            output = self(train_data)
            loss = criterion(output, train_labels)
            loss.backward()
            optimizer1.step()    # Does the update
            
            train_loss.append(loss.cpu().detach().numpy())
            if verbose!=0 and e%verbose==0:
                print("Loss - train :")
                print(loss)
            if val_data is not None:
                output = self(val_data)
                loss = criterion(output, val_labels)
                if verbose!=0 and e%verbose==0:
                    print("Loss - validation :")
                    print(loss)
                val_loss.append(loss.cpu().detach().numpy())

        if(plot_val):    
            plot_loss(train_loss, 'train-loss')
            if len(val_loss)>0:
                plot_loss(val_loss, 'val-loss', color='red')

    def accuracy(self, data, true_labers):
        num_ok = 0
        for idx, test in enumerate(data):
            output = net(test.type(torch.float))
            target = true_labers[idx]
            if output.max(0)[1] == target:
                num_ok += 1
        return num_ok / len(data)

#define net
net = Net(2,2,2)
net.to(device)
print(net)

#train from all examples from train set
net.train((train_data_scaled_tensor).type(torch.float), (train_labels_tensor).type(torch.long), 
        epochs=1000,lr=0.1,verbose=100)

# evaluate one example from test set
input = test_data_scaled_tensor[0][:]
print(input)
output = net(input.type(torch.float))
print(output)
print(output.max(0)[1])
target = test_labels_tensor[0]
print(target)

# evaluate net from all examples from test set
num_ok = 0
C = np.zeros([2, 2])

for idx, test in enumerate(test_data_scaled_tensor):
    output = net(test.type(torch.float))
    target = test_labels_tensor[idx]
    C[int(test_labels_tensor[idx])][int(output.max(0)[1])] += 1
    if output.max(0)[1] == target:
        num_ok += 1

print('acc = ' + str(num_ok / len(test_data_scaled_tensor)))

print(C)

# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(C, classes=range(2), title='Confusion matrix, without normalization')

# Plot normalized confusion matrix
plt.figure()
plot_confusion_matrix(C, classes=range(2), normalize=True,
                      title='Normalized confusion matrix')

plt.show()

"""# **Classify gestures by reading muscle activity.**
## A recording of human hand muscle activity producing four different hand gestures
"""

classes = {0: 'rock', 1: 'scissors', 2: 'paper', 3: 'ok'}

import pandas as pd 
import glob

pd.set_option("display.precision", 2)

# read data (4 csv file and put them in one list with 4 file streams)
data = []
for i in range(len(glob.glob(data_dir_drive + '*.csv'))):
    data.append(pd.read_csv(data_dir_drive + str(i) + '.csv')) 

# Preview the first 5 lines of the loaded data for each table
for i in range(len(glob.glob(data_dir_drive + '*.csv'))):
    print(data_dir_drive + str(i) + '.csv')
    print(data[i].head())

data[0].head()

print(data[0].columns)
# print the shape of tables
for i in range(len(glob.glob(data_dir_drive + '*.csv'))):
    print(data_dir_drive + str(i) + '.csv')
    print(data[i].shape)

# print same iformations about each column for table 1
print(data[0].info())

"""## **Data Analysis**"""

# The describe method shows basic statistical characteristics of each 
# numerical feature (int64 and float64 types): number of non-missing values, 
# mean, standard deviation, range, median, 0.25 and 0.75 quartiles.
data[0].describe()

import matplotlib.pyplot as plt

"""Data distribution for ***rock*** gesture, of the same muscle in all 8 consecutive readings"""

# get columns to plot
columns = []
for c in range(0, 64, 8):
    columns.append(data[0].columns[c])
# create x data
x_data = range(0, data[0].shape[0])
# create figure and axis
fig, ax = plt.subplots()
fig.set_size_inches(100, 20, forward=True)
# plot each column
for column in columns:
    ax.plot(x_data, data[0][column], label=column)
# set title and legend
ax.set_title('EMG Dataset for class 0 and sensor 1 (8 readings)')
ax.legend()

for column in data[0].columns:
    data[0][column].plot.hist()

data[0][data[0].columns[:64]].plot.hist(subplots=True, layout=(8,8), figsize=(25, 25), bins=50)

"""## Label distribution
*It can easily see that the classes are balanced*
"""

import matplotlib.pyplot as plt; plt.rcdefaults()
import numpy as np
import matplotlib.pyplot as plt

objects = classes.values()
y_pos = np.arange(len(objects))
nr = [len(data[i]) for i in range(4)]

plt.barh(y_pos, nr, align='center', alpha=0.5)
plt.yticks(y_pos, objects)
plt.xlabel('Number of data per label')
plt.title('Label distribution')

plt.show()

for idx, clas in classes.items():
    print(clas + ': ' + str(len(data[idx])))

"""## **Split data in train and test**
First of all the label of a gesture is extracted from all the information.

The dataset is divided in two categories: training and test.

The first one will be, obviously, used for trainig; the validation set will be used to measure the model performance during training and the test set will be used to evaluate our model performance once the training has finished.

Note: These two sets should all contain different datas.
"""

npData = np.concatenate((data[0].to_numpy(), data[1].to_numpy(), data[2].to_numpy(), data[3].to_numpy()))
print(npData.shape)

Tdata = np.transpose(npData)
Labels = np.transpose(Tdata[-1])
pureData = np.transpose(Tdata[:-1])

print(pureData.shape)
print(Labels.shape)

# shuffle data
randPerm = np.random.permutation((npData.shape)[0])
pureDataRand = pureData[randPerm][:]
LabelsRand = Labels[randPerm][:]

import math

train_size = 10000
test_size = (pureDataRand.shape)[0] - train_size
train_data = pureDataRand[0:train_size][:]
train_labels = LabelsRand[0:train_size][:]
test_data = pureDataRand[train_size:][:]
test_labels = LabelsRand[train_size:][:]
print(train_size)
print(test_size)
print(train_data.shape)
print(train_labels.shape)
print(test_data.shape)
print(test_labels.shape)

"""## **Normalize data**

![scaling.png](https://avinton.com/wp-content/uploads/2017/11/centering-standadization.png)
"""

from sklearn import preprocessing # import the preprocessing library
 
# define the normalizer
scaler = preprocessing.StandardScaler()
# compute the mean and the std on the training set
scaler.fit(train_data)

# print the mean
print('mean =', scaler.mean_.shape)  
# print the standard deviation
print('std =', scaler.scale_.shape) 

# scaling the training data
train_data_scaled = scaler.transform(train_data)
print(train_data_scaled.shape)  

# scaling the test data
test_data_scaled = scaler.transform(test_data)
print(test_data_scaled.shape)

"""## **Bayesian Neural Networks**"""

in_size = train_data_scaled.shape[1]
hidden1_size = 512
hidden2_size = 128
out_size = 4

EPOCH_NUM = 10
BATCH_SIZE = 1000

import edward as ed
from edward.models import Normal, Categorical, Bernoulli
import tensorflow as tf

data_placeholder = tf.placeholder(tf.float32, shape=(None, in_size))
label_placeholder = tf.placeholder(tf.int32, shape=(BATCH_SIZE))

w1 = Normal(loc=tf.zeros([in_size, hidden1_size]), scale=tf.ones([in_size, hidden1_size]))
w2 = Normal(loc=tf.zeros([hidden1_size, hidden2_size]), scale=tf.ones([hidden1_size, hidden2_size]))
w3 = Normal(loc=tf.zeros([hidden2_size, out_size]), scale=tf.ones([hidden2_size, out_size]))
b1 = Normal(loc=tf.zeros([hidden1_size]), scale=tf.ones([hidden1_size]))
b2 = Normal(loc=tf.zeros([hidden2_size]), scale=tf.ones([hidden2_size]))
b3 = Normal(loc=tf.zeros([out_size]), scale=tf.ones([out_size]))

act_1 = tf.nn.relu(tf.matmul(data_placeholder, w1) + b1)
act_2 = tf.nn.relu(tf.matmul(act_1, w2) + b2)
act_out = tf.nn.softmax(tf.matmul(act_2, w3) + b3)

out_pre = Categorical(act_out)

qw1 = Normal(loc=tf.Variable(tf.random_normal([in_size, hidden1_size])), scale=tf.Variable(tf.random_normal([in_size, hidden1_size])))
qw2 = Normal(loc=tf.Variable(tf.random_normal([hidden1_size, hidden2_size])), scale=tf.Variable(tf.random_normal([hidden1_size, hidden2_size])))
qw3 = Normal(loc=tf.Variable(tf.random_normal([hidden2_size, out_size])), scale=tf.Variable(tf.random_normal([hidden2_size, out_size])))
qb1 = Normal(loc=tf.Variable(tf.random_normal([hidden1_size])), scale=tf.Variable(tf.random_normal([hidden1_size])))
qb2 = Normal(loc=tf.Variable(tf.random_normal([hidden2_size])), scale=tf.Variable(tf.random_normal([hidden2_size])))
qb3 = Normal(loc=tf.Variable(tf.random_normal([out_size])), scale=tf.Variable(tf.random_normal([out_size])))

act_1_ = tf.nn.relu(tf.matmul(data_placeholder, qw1) + qb1)
act_2_ = tf.nn.relu(tf.matmul(act_1_, qw2) + qb2)
act_out_ = tf.nn.softmax(tf.matmul(act_2_,qw3) + qb3)
out = Categorical(act_out_)

inference = ed.KLqp({w1: qw1, w2: qw2, w3: qw3, b1: qb1, b2: qb2, b3: qb3}, data={out_pre: label_placeholder})
inference.initialize()

sess = tf.Session()
sess.run(tf.global_variables_initializer())

t, v = [], []

with sess:
    samples_num = 1000
    for epoch in range(EPOCH_NUM):
        perm = np.random.permutation(train_size)
        for i in range(0, train_size, BATCH_SIZE):
            batch_data = train_data_scaled[perm[i:i+BATCH_SIZE]]
            batch_labels = train_labels[perm[i:i+BATCH_SIZE]]
            inference.update(feed_dict={data_placeholder: batch_data, label_placeholder: batch_labels})
        labels_samples = out.sample(samples_num).eval(feed_dict={data_placeholder: train_data_scaled})
        accs = []
        for lb in labels_samples:
            accs.append((lb == train_labels).mean())
        acc = np.array(accs).mean()
        t.append(acc)
        labels_samples = out.sample(samples_num).eval(feed_dict={data_placeholder: test_data_scaled})
        accs = []
        for lb in labels_samples:
            accs.append((lb == test_labels).mean())
        test_acc = np.array(accs).mean()
        v.append(test_acc)
        print('epoch:\t'+ str(epoch+1) + '\taccuracy:\t' + str(acc) + '\tvaridation accuracy:\t' + str(test_acc))
    print('accuracy = ' + str(test_acc * 100) + '%')

e = range(1, EPOCH_NUM+1)
plt.plot(e, t, '-b', e, v, '-r')
plt.show()

"""## **Training MLP**"""

import torch

# using CUDA (GPU) if is possible
CUDA_LAUNCH_BLOCKING=1

plt.ion()  

if torch.cuda.is_available():
    device = torch.device('cuda')
    print("Using CUDA")
else:
    device = torch.device('cpu')
    print("Using CPU")

# transform all fata to tensors and move to GPU
train_data_scaled_tensor = torch.Tensor(train_data_scaled).to(device)
train_labels_tensor = torch.Tensor(train_labels).to(device)
test_data_scaled_tensor = torch.Tensor(test_data_scaled).to(device)
test_labels_tensor = torch.Tensor(test_labels).to(device)

import matplotlib.pyplot as plt

# plot loss function
def plot_loss(loss, label, color='blue'):
    plt.plot(loss, label=label, color=color)
    plt.legend()

"""### **Training**
What follows is pretty standard pytorch code for training.

For every epoch we iterate over all the training set, compute the loss , and adjust the network weights with loss.backward() and optimizer.step(). Then we evaluate the performance over the validaton set. At the end of every epoch we print the network progress (loss and accuracy). The accuracy will tell us how many predictions were correct.

As we said before, transfer learning can work on smaller dataset too, so for every epoch we only iterate over half the trainig dataset (worth noting that it won't exactly be half of it over the entire training, as the data is shuffled, but it will almost certainly be a subset)
"""

import torch.nn as nn
import torch.nn.functional as F

class Net(nn.Module):
    # nn.Module - base class for all models
    # easy acces to .parameters() and .zero_grad()
    # define .forward() instead of __call__()
    
    def __init__(self, in_size, h_size1, h_size2, out_size, p = 0.05):
        super().__init__()
        self._layer1 = nn.Linear(in_size,h_size1).to(device)
        self._layer2 = nn.Linear(h_size1,h_size2).to(device)
        self._layer3 = nn.Linear(h_size2,out_size).to(device)
        
    def forward(self, x):
        x = F.relu(self._layer1(x)).to(device)
        x = F.relu(self._layer2(x)).to(device)
        x = self._layer3(x).to(device)
        x = F.softmax(x).to(device)
        return x.to(device)
        
    def train(self, train_data, train_labels, 
              epochs=400, lr=0.01, verbose=100, l2_weight=0,
              val_data=None, val_labels=None, plot_val = True):
        #use optimizers to take care of the update step
        optimizer1 = torch.optim.SGD(self.parameters(), lr=lr,
                               weight_decay = l2_weight)
        optimizer2 = torch.optim.Adagrad(self.parameters(), lr=lr,
                               weight_decay = l2_weight)
        optimizer3 = torch.optim.RMSprop(self.parameters(), lr=lr,
                               weight_decay = l2_weight)
        optimizer4 = torch.optim.Adam(self.parameters(), lr=lr,
                               weight_decay = l2_weight)
        
        criterion = nn.CrossEntropyLoss();
        
        train_loss = []
        val_loss = []
        for e in range(epochs):
            optimizer1.zero_grad()   # zero the gradient buffers
            input = train_data
            output = self(train_data)
            loss = criterion(output, train_labels)
            loss.backward()
            optimizer1.step()    # Does the update
            
            train_loss.append(loss.cpu().detach().numpy())
            if verbose!=0 and e%verbose==0:
                print("Loss - train :")
                print(loss)
            if val_data is not None:
                output = self(val_data)
                loss = criterion(output, val_labels)
                if verbose!=0 and e%verbose==0:
                    print("Loss - validation :")
                    print(loss)
                val_loss.append(loss.cpu().detach().numpy())

        if(plot_val):    
            plot_loss(train_loss, 'train-loss')
            if len(val_loss)>0:
                plot_loss(val_loss, 'val-loss', color='red')

    def accuracy(self, data, true_labers):
        num_ok = 0
        for idx, test in enumerate(data):
            output = net(test.type(torch.float))
            target = true_labers[idx]
            if output.max(0)[1] == target:
                num_ok += 1
        return num_ok / len(data)

#define net
net = Net(64, 512, 128, 4)
net.to(device)
print(net)

#train from 2 examples from train set
input = train_data_scaled_tensor[0:2][:]
print(input.shape)
output = net(input.type(torch.float))
print(output.shape)
target = train_labels_tensor[0:2][:]
print(target.shape)

criterion = nn.CrossEntropyLoss()

loss = criterion(output, target.type(torch.long))
print(loss)

#train from all examples from train set
net.train((train_data_scaled_tensor).type(torch.float), (train_labels_tensor).type(torch.long), 
        epochs=1000,lr=0.1,verbose=100)

# evaluate one example from test set
input = test_data_scaled_tensor[0][:]
print(input)
output = net(input.type(torch.float))
print(output)
print(output.max(0)[1])
target = test_labels_tensor[0]
print(target)

# evaluate net from all examples from test set
num_ok = 0
C = np.zeros([4, 4])

for idx, test in enumerate(test_data_scaled_tensor):
    output = net(test.type(torch.float))
    target = test_labels_tensor[idx]
    C[int(test_labels_tensor[idx])][int(output.max(0)[1])] += 1
    if output.max(0)[1] == target:
        num_ok += 1

print('acc = ' + str(num_ok / len(test_data_scaled_tensor)))

print(C)

# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(C, classes=classes.values(), title='Confusion matrix, without normalization')

# Plot normalized confusion matrix
plt.figure()
plot_confusion_matrix(C, classes=classes.values(), normalize=True,
                      title='Normalized confusion matrix')

plt.show()

"""## **Learning only on the first reading of the muscles, not on all 8 readings**"""

#define net
net = Net(8, 512, 128, 4)
net.to(device)
print(net)

train_data_scaled_tensor_first = train_data_scaled_tensor[:, :8]
test_data_scaled_tensor_first = test_data_scaled_tensor[:, :8]

#train from all examples from train set
net.train((train_data_scaled_tensor_first).type(torch.float), (train_labels_tensor).type(torch.long), 
        epochs=1000,lr=0.1,verbose=100)

print(net.accuracy(test_data_scaled_tensor_first, test_labels_tensor))

"""# **Extras**

# **Siamese Net**

## **Build Data Set**
From emg DataSet - Classify gestures by reading muscle activity.
"""

print(pureData.shape)
print(Labels.shape)

# shuffle data
randPerm = np.random.permutation((npData.shape)[0])
pureDataRand = pureData[randPerm][:]
LabelsRand = Labels[randPerm][:]

import math

train_size = 10000
test_size = (pureDataRand.shape)[0] - train_size
train_data = pureDataRand[0:train_size][:]
train_labels = LabelsRand[0:train_size][:]
test_data = pureDataRand[train_size:][:]
test_labels = LabelsRand[train_size:][:]
print(train_size)
print(test_size)
print(train_data.shape)
print(train_labels.shape)
print(test_data.shape)
print(test_labels.shape)

from sklearn import preprocessing # import the preprocessing library
 
# define the normalizer
scaler = preprocessing.StandardScaler()
# compute the mean and the std on the training set
scaler.fit(train_data)

# print the mean
print('mean =', scaler.mean_.shape)  
# print the standard deviation
print('std =', scaler.scale_.shape) 

# scaling the training data
train_data_scaled = scaler.transform(train_data)
print(train_data_scaled.shape)  

# scaling the test data
test_data_scaled = scaler.transform(test_data)
print(test_data_scaled.shape)

# generate 2 examples and the label for those
def generate_1batch(train_data, labels):
    # shuffle data
    randPerm1 = np.random.permutation((train_data.shape)[0])
    train_data1 = train_data[randPerm1][:]
    labels1 = labels[randPerm1][:]

    randPerm2 = np.random.permutation((train_data.shape)[0])
    train_data2 = train_data[randPerm2][:]
    labels2 = labels[randPerm2][:]

    size = 1

    labels_siamese = np.array(labels1[:size]!=labels2[:size],dtype=np.int32)

    return train_data1[:size, :], train_data2[:size, :], labels_siamese

# generate size examples and the labels for those
# more than that in a batch for siamese networks must be data with same label

def generate_more_batches(train_data, labels, size = 64):
    class_lab = np.random.randint(2, size=1)[0]
    # shuffle data
    randPerm1 = np.random.permutation((train_data.shape)[0])
    train_data1 = train_data[randPerm1][:]
    labels1 = labels[randPerm1][:]

    randPerm2 = np.random.permutation((train_data.shape)[0])
    train_data2 = train_data[randPerm2][:]
    labels2 = labels[randPerm2][:]

    labels_siamese = np.array(labels1!=labels2,dtype=np.int32)

    idxs = labels_siamese == class_lab

    train_data1 = train_data1[idxs, :]
    train_data2 = train_data2[idxs, :]

    return train_data1[:size, :], train_data2[:size, :], [class_lab]

d0, d1, label = generate_more_batches(train_data_scaled, train_labels)

# testing generate_more_batches(...)
for e in range(64):
    a, b = 0, 0
    for i, data in enumerate(train_data_scaled):
        if (data == d0[e]).all():
            a = train_labels[i]
        if (data == d1[e]).all():
            b = train_labels[i]
    print(a, b)

"""## **Bayesian Siamese Net**"""

# exacly as F.pairwise_distance
def pairwise_dist (A, B):  
  """
  Computes pairwise distances between each elements of A and each elements of B.
  Args:
    A,    [m,d] matrix
    B,    [n,d] matrix
  Returns:
    D,    [m,n] matrix of pairwise distances
  """
  with tf.variable_scope('pairwise_dist'):
    # squared norms of each row in A and B
    na = tf.reduce_sum(tf.square(A), 1)
    nb = tf.reduce_sum(tf.square(B), 1)
    
    # na as a row and nb as a co"lumn vectors
    na = tf.reshape(na, [-1, 1])
    nb = tf.reshape(nb, [1, -1])

    # return pairwise euclidead difference matrix
    D = tf.sqrt(tf.maximum(na - 2*tf.matmul(A, B, False, True) + nb, 0.0))
  return D

in_size = train_data_scaled.shape[1]
hidden_size1 = 512
hidden_size2 = 512
out_size = 2

EPOCH_NUM = 10
BATCH_SIZE = 100

data_placeholder1 = tf.placeholder(tf.float32, shape=(None, in_size))
data_placeholder2 = tf.placeholder(tf.float32, shape=(None, in_size))
label_placeholder = tf.placeholder(tf.int32, shape=(BATCH_SIZE))

# net 1
w1 = Normal(loc=tf.zeros([in_size, hidden_size1]), scale=tf.ones([in_size, hidden_size1]))
w2 = Normal(loc=tf.zeros([hidden_size1, hidden_size2]), scale=tf.ones([hidden_size1, hidden_size2]))
w3 = Normal(loc=tf.zeros([hidden_size2, out_size]), scale=tf.ones([hidden_size2, out_size]))
b1 = Normal(loc=tf.zeros([hidden_size1]), scale=tf.ones([hidden_size1]))
b2 = Normal(loc=tf.zeros([hidden_size2]), scale=tf.ones([hidden_size2]))
b3 = Normal(loc=tf.zeros([out_size]), scale=tf.ones([out_size]))

# net 2
ww1 = Normal(loc=tf.zeros([in_size, hidden_size1]), scale=tf.ones([in_size, hidden_size1]))
ww2 = Normal(loc=tf.zeros([hidden_size1, hidden_size2]), scale=tf.ones([hidden_size1, hidden_size2]))
ww3 = Normal(loc=tf.zeros([hidden_size2, out_size]), scale=tf.ones([hidden_size2, out_size]))
bb1 = Normal(loc=tf.zeros([hidden_size1]), scale=tf.ones([hidden_size1]))
bb2 = Normal(loc=tf.zeros([hidden_size2]), scale=tf.ones([hidden_size2]))
bb3 = Normal(loc=tf.zeros([out_size]), scale=tf.ones([out_size]))

act_1 = tf.nn.relu(tf.matmul(data_placeholder1, w1) + b1)
act_2 = tf.nn.relu(tf.matmul(act_1, w2) + b2)
act_out1 = tf.matmul(act_2,w3) + b3

act_3 = tf.nn.relu(tf.matmul(data_placeholder2, ww1) + bb1)
act_4 = tf.nn.relu(tf.matmul(act_3, w2) + bb2)
act_out2 = tf.matmul(act_4, ww3) + bb3

# net 1 unified with net 2 through pairwise_dist
out_pre = Categorical(pairwise_dist(act_out1, act_out2))

qw1 = Normal(loc=tf.Variable(tf.random_normal([in_size, hidden_size1])), scale=tf.Variable(tf.random_normal([in_size, hidden_size1])))
qw2 = Normal(loc=tf.Variable(tf.random_normal([hidden_size1, hidden_size2])), scale=tf.Variable(tf.random_normal([hidden_size1, hidden_size2])))
qw3 = Normal(loc=tf.Variable(tf.random_normal([hidden_size2, out_size])), scale=tf.Variable(tf.random_normal([hidden_size2, out_size])))
qb1 = Normal(loc=tf.Variable(tf.random_normal([hidden_size1])), scale=tf.Variable(tf.random_normal([hidden_size1])))
qb2 = Normal(loc=tf.Variable(tf.random_normal([hidden_size2])), scale=tf.Variable(tf.random_normal([hidden_size2])))
qb3 = Normal(loc=tf.Variable(tf.random_normal([out_size])), scale=tf.Variable(tf.random_normal([out_size])))

qww1 = Normal(loc=tf.Variable(tf.random_normal([in_size, hidden_size1])), scale=tf.Variable(tf.random_normal([in_size, hidden_size1])))
qww2 = Normal(loc=tf.Variable(tf.random_normal([hidden_size1, hidden_size2])), scale=tf.Variable(tf.random_normal([hidden_size1, hidden_size2])))
qww3 = Normal(loc=tf.Variable(tf.random_normal([hidden_size2, out_size])), scale=tf.Variable(tf.random_normal([hidden_size2, out_size])))
qbb1 = Normal(loc=tf.Variable(tf.random_normal([hidden_size1])), scale=tf.Variable(tf.random_normal([hidden_size1])))
qbb2 = Normal(loc=tf.Variable(tf.random_normal([hidden_size2])), scale=tf.Variable(tf.random_normal([hidden_size2])))
qbb3 = Normal(loc=tf.Variable(tf.random_normal([out_size])), scale=tf.Variable(tf.random_normal([out_size])))

act_1_ = tf.nn.relu(tf.matmul(data_placeholder1, qw1) + qb1)
act_2_ = tf.nn.relu(tf.matmul(act_1_, qw2) + qb2)
act_out1_ = tf.matmul(act_2_,qw3) + qb3

act_3_ = tf.nn.relu(tf.matmul(data_placeholder2, qww1) + qbb1)
act_4_ = tf.nn.relu(tf.matmul(act_3, qw2) + qbb2)
act_out2_ = tf.matmul(act_4, qww3) + qbb3

# same as above
out = Categorical(pairwise_dist(act_out1_, act_out2_))

inference = ed.KLqp({w1: qw1, w2: qw2, w3: qw3, b1: qb1, b2: qb2, b3: qb3,
                     ww1: qww1, ww2: qww2, ww3: qww3, bb1: qbb1, bb2: qbb2, bb3: qbb3}, data={out_pre: label_placeholder})
inference.initialize()

sess = tf.Session()
sess.run(tf.global_variables_initializer())

t, v = [], []

with sess:
    samples_num = 1000
    for epoch in range(EPOCH_NUM):
        for _ in range(0,train_size,BATCH_SIZE):
            d0, d1 ,label = generate_more_batches(train_data_scaled, train_labels, BATCH_SIZE)
            label = np.array(label)
            label = np.repeat(label, BATCH_SIZE)
            inference.update(feed_dict={data_placeholder1: d0, data_placeholder2: d1, label_placeholder: label})

        acc = []
        test_acc = []

        for _ in range(10):
            d0, d1 ,label = generate_more_batches(train_data_scaled, train_labels, 100)
            labels_samples = out.sample(samples_num).eval(feed_dict={data_placeholder1: d0, data_placeholder2: d1})
            acc.append(int((np.round(labels_samples.mean(axis=0) / 100)).mean() == label))

            d0, d1 ,label = generate_more_batches(test_data_scaled, test_labels, 10)
            labels_samples = out.sample(samples_num).eval(feed_dict={data_placeholder1: d0, data_placeholder2: d1})
            test_acc.append(int((np.round(labels_samples.mean(axis=0) / 100)).mean() == label))

        t.append(np.array(acc).mean())
        v.append(np.array(test_acc).mean())

        print('epoch:\t'+ str(epoch+1) + '\taccuracy:\t' + str(np.array(acc).mean()) + '\tvaridation accuracy:\t' + str(np.array(test_acc).mean()))
    print('accuracy = ' + str(np.array(test_acc).mean() * 100) + '%')

e = range(1, EPOCH_NUM+1)
plt.plot(e, t, '-b', e, v, '-r')
plt.show()

"""## **MLP Siamese Net Definition**"""

class SiameseNetwork(nn.Module):
    def __init__(self):
        super(SiameseNetwork, self).__init__()

        self.fc1 = nn.Sequential(
            nn.Linear(64, 512),
            nn.ReLU(inplace=True),

            nn.Linear(512, 512),
            nn.ReLU(inplace=True),

            nn.Linear(512, 4))

    def forward_once(self, x):
        return self.fc1(x)

    def forward(self, input1, input2):
        output1 = self.forward_once(input1)
        output2 = self.forward_once(input2)
        return output1, output2

"""## **Contrastive Loss**"""

class ContrastiveLoss(torch.nn.Module):
    """
    Contrastive loss function.
    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf
    """

    def __init__(self, margin=3.0):
        super(ContrastiveLoss, self).__init__()
        self.margin = margin

    def forward(self, output1, output2, label):
        euclidean_distance = F.pairwise_distance(output1, output2, keepdim = True)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) / 2 +
                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2) / 2)

        return loss_contrastive

"""## **Training Time!**"""

import torch.nn.functional as F
import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
from torch.autograd import Variable

net = SiameseNetwork().cuda()
criterion = ContrastiveLoss()
optimizer = optim.Adam(net.parameters(),lr = 0.00001 )

d0, d1, label = generate_1batch(train_data_scaled, train_labels)

d0 = torch.from_numpy(d0).cuda()
d1 = torch.from_numpy(d1).cuda()
label = torch.from_numpy(label).cuda()

optimizer.zero_grad()
output1,output2 = net(d0.float(), d1.float())
print(label)
print(output1)
print(output2)

def init():
    counter = []
    loss_history = [] 
    iteration_number= 0
    return counter, loss_history, iteration_number

def show_plot(iteration,loss):
    plt.plot(iteration,loss)
    plt.show()

counter, loss_history, iteration_number = init()
for epoch in range(10):
    i = 0
    BATCH_SIZE = 64
    for _ in range(0,train_size,BATCH_SIZE):
        d0, d1 , label = generate_more_batches(train_data_scaled, train_labels, BATCH_SIZE)
        label = np.array(label)

        d0 = torch.from_numpy(d0).cuda()
        d1 = torch.from_numpy(d1).cuda()
        label = torch.from_numpy(label).cuda()

        optimizer.zero_grad()
        output1,output2 = net(d0.float(),d1.float())
        loss_contrastive = criterion(output1,output2,label)
        loss_contrastive.backward()
        optimizer.step()
        i = i + 1
        if i %10 == 0 :
            print("Epoch number {}\n Current loss {}\n".format(epoch,loss_contrastive.item()))
            iteration_number +=10
            counter.append(iteration_number)
            loss_history.append(loss_contrastive.item())
show_plot(counter,loss_history)

epochs = []
losses = []

for i in range(0, len(counter), 100):
    epochs.append(counter[i])
    losses.append(np.array(loss_history)[i:i+100].mean())

epochs.append(counter[-1])
losses.append(np.array(loss_history)[i:].mean())

plt.plot(counter,loss_history, epochs, losses, '-r')
plt.show()

import math 
accs = []

for _ in range(100):
    d0, d1 , label = generate_more_batches(test_data_scaled, test_labels, 50)

    d0 = torch.from_numpy(d0).cuda()
    d1 = torch.from_numpy(d1).cuda()

    output1,output2 = net(d0.float(),d1.float())

    euclidean_distance = F.pairwise_distance(output1, output2)
    euclidean_distance = euclidean_distance.mean()
    accs.append(int(math.trunc(euclidean_distance.item()) == label[0]))

print(np.array(accs).mean())

"""More infos about siamese netorks see: https://github.com/marianlupascu/Undergraduate-Thesis pages 47-54 (from Thesis)"""