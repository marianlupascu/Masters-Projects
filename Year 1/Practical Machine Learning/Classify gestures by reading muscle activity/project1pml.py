# -*- coding: utf-8 -*-
"""Project1PML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IlOwB82cyxp8I5ZElQCzH0s_TskF9HlS

# **Classify gestures by reading muscle activity.**
## A recording of human hand muscle activity producing four different hand gestures
"""

from google.colab import files, auth, drive
import numpy as np

# Mount to Google drive
drive.mount('/content/gdrive', force_remount=True)
data_dir_drive ='/content/gdrive/My Drive/Colab Notebooks/PML/Proj1/'

# Unzip dataset to /content
import time

start = time.time()

!unzip -u '/content/gdrive/My Drive/Colab Notebooks/PML/Proj1/emg-4.zip' -d '/content/gdrive/My Drive/Colab Notebooks/PML/Proj1/'

print('Took', (time.time() - start), ' secundes to unzip')

! ls '/content/gdrive/My Drive/Colab Notebooks/PML/Proj1/'

"""# **Utils**
Some utility function to visualize the dataset and the model's predictions
"""

import itertools
import matplotlib.pyplot as plt

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

classes = {0: 'rock', 1: 'scissors', 2: 'paper', 3: 'ok'}

import pandas as pd 
import glob

pd.set_option("display.precision", 2)

# read data (4 csv file and put them in one list with 4 file streams)
data = []
for i in range(len(glob.glob(data_dir_drive + '*.csv'))):
    data.append(pd.read_csv(data_dir_drive + str(i) + '.csv')) 

# Preview the first 5 lines of the loaded data for each table
for i in range(len(glob.glob(data_dir_drive + '*.csv'))):
    print(data_dir_drive + str(i) + '.csv')
    print(data[i].head())

data[0].head()

# print the shape of tables
for i in range(len(glob.glob(data_dir_drive + '*.csv'))):
    print(data_dir_drive + str(i) + '.csv')
    print(data[i].shape)

# print column name for table 1 (rock dataset)
print(data[0].columns)

# print same iformations about each column for table 1
print(data[0].info())

"""# **Data Analysis**"""

# The describe method shows basic statistical characteristics of each 
# numerical feature (int64 and float64 types): number of non-missing values, 
# mean, standard deviation, range, median, 0.25 and 0.75 quartiles.
data[0].describe()

import matplotlib.pyplot as plt

"""Data distribution for ***rock*** gesture, of the same muscle in all 8 consecutive readings"""

# get columns to plot
columns = []
for c in range(0, 64, 8):
    columns.append(data[0].columns[c])
# create x data
x_data = range(0, data[0].shape[0])
# create figure and axis
fig, ax = plt.subplots()
fig.set_size_inches(100, 20, forward=True)
# plot each column
for column in columns:
    ax.plot(x_data, data[0][column], label=column)
# set title and legend
ax.set_title('EMG Dataset for class 0 and sensor 1 (8 readings)')
ax.legend()

for column in data[0].columns:
    data[0][column].plot.hist()

"""***rock*** gesture data distribution for all 8 muscles and 8 reads"""

data[0][data[0].columns[:64]].plot.hist(subplots=True, layout=(8,8), figsize=(25, 25), bins=50)

"""## Label distribution
*It can easily see that the classes are balanced*
"""

import matplotlib.pyplot as plt; plt.rcdefaults()
import numpy as np
import matplotlib.pyplot as plt

objects = classes.values()
y_pos = np.arange(len(objects))
nr = [len(data[i]) for i in range(4)]

plt.barh(y_pos, nr, align='center', alpha=0.5)
plt.yticks(y_pos, objects)
plt.xlabel('Number of data per label')
plt.title('Label distribution')

plt.show()

for idx, clas in classes.items():
    print(clas + ': ' + str(len(data[idx])))

"""# **Split data in train, validation and test**
First of all the label of a gesture is extracted from all the information.

The dataset is divided in three categories: training, validation and test.

The first one will be, obviously, used for trainig; the validation set will be used to measure the model performance during training and the test set will be used to evaluate our model performance once the training has finished.

Note: These three sets should all contain different datas.
"""

npData = np.concatenate((data[0].to_numpy(), data[1].to_numpy(), data[2].to_numpy(), data[3].to_numpy()))
print(npData.shape)

Tdata = np.transpose(npData)
Labels = np.transpose(Tdata[-1])
pureData = np.transpose(Tdata[:-1])

# shuffle data
randPerm = np.random.permutation((npData.shape)[0])
pureDataRand = pureData[randPerm][:]
LabelsRand = Labels[randPerm][:]

import math

train_size = math.floor(0.8 * (pureDataRand.shape)[0])
val_size = math.floor(0.1 * (pureDataRand.shape)[0])
test_size = (pureDataRand.shape)[0] - train_size - val_size
train_data = pureDataRand[0:train_size][:]
train_labels = LabelsRand[0:train_size][:]
val_data = pureDataRand[train_size:train_size + val_size][:]
val_labels = LabelsRand[train_size:train_size + val_size][:]
test_data = pureDataRand[train_size + val_size :][:]
test_labels = LabelsRand[train_size + val_size :][:]
print(train_size)
print(val_size)
print(test_size)
print(train_data.shape)
print(train_labels.shape)
print(val_data.shape)
print(val_labels.shape)
print(test_data.shape)
print(test_labels.shape)

"""# **Normalize data**

![scaling.png](https://avinton.com/wp-content/uploads/2017/11/centering-standadization.png)
"""

from sklearn import preprocessing # import the preprocessing library
 
# define the normalizer
scaler = preprocessing.StandardScaler()
# compute the mean and the std on the training set
scaler.fit(train_data)

# print the mean
print('mean =', scaler.mean_.shape)  
# print the standard deviation
print('std =', scaler.scale_.shape) 

# scaling the training data
train_data_scaled = scaler.transform(train_data)
print(train_data_scaled.shape)  

# scaling the val data
val_data_scaled = scaler.transform(val_data)
print(val_data_scaled.shape)    

# scaling the test data
test_data_scaled = scaler.transform(test_data)
print(test_data_scaled.shape)

"""# **Training - SVM**

![svm.png](https://miro.medium.com/max/1200/1*06GSco3ItM3gwW2scY6Tmg.png)
In the left side, we have some possible decision functions that correctly classify (separate) the two classes (blue circles and red squares). In the right side, we have the decision function of an SVM that chooses the maximal margin between the two classes. 

![tehn.png](https://i.stack.imgur.com/zKpJy.jpg)
 
The first technique is __OneVsAll__:
    - using this approach K (number of classes) classifiers are trained, one classifier for each class in order to separate that class from the rest. The final label is given by the classifier with the maximum score.
    
The second technique is __OneVsOne__:
    - using this approch K * (K - 1) / 2 classifiers are trained, one classifier for each pair of two classes. The final label is given by the majority label.
"""

from sklearn import svm # import the library

# plot the data
# here for all first 1000 data from train see data in 2D by feature 0 and 1
for i in range(1000):
    if train_labels[i] == 0:
        plt.plot(train_data_scaled[i, 0], train_data_scaled[i, 1], 'og')
    elif train_labels[i] == 1:
        plt.plot(train_data_scaled[i, 0], train_data_scaled[i, 1], 'or')
    elif train_labels[i] == 2:
        plt.plot(train_data_scaled[i, 0], train_data_scaled[i, 1], 'xb')
    else:
        plt.plot(train_data_scaled[i, 0], train_data_scaled[i, 1], 'xy')
plt.show()

# train a SVM model
C_param = 1
# or decision_function_shape='ovr'
svm_model = svm.SVC(C_param, decision_function_shape='ovo', class_weight='balanced') # define the model
print(svm_model)

"""### The regularization parameter and **grid search for C param**

C is the regularization parameter and controls the error of the classifier on the training set.
    - if C is big, a hyperplane with a small separation margin will be chosen, if this has better performance on the training set. (it can overfit).
    - if C is small, a hyperplane with a bigger separation margin will be chosen, even if this hyperplane does not separate the training set perfectly. (it can underfit). 
![C_param.png](https://qph.fs.quoracdn.net/main-qimg-c49906cb927e21fce85624c589762b5d)

In the left it is used a bigger C, in the right it's used a smaller C and the hyperplane does not separate perfectly the training set.
"""

from sklearn.metrics import accuracy_score

svm_model.fit(train_data_scaled, train_labels) # train

predicted_labels_test = svm_model.predict(test_data_scaled) # predit
print(accuracy_score(test_labels, predicted_labels_test))

val_acc = accuracy_score(val_labels, svm_model.predict(val_data_scaled))

C_param_list = np.logspace(0, 3, 25, endpoint=True, base = 10) - 0.99
print(C_param_list)

svm_best = svm_model
acc_best = val_acc
C_opt = C_param

C_params = []
accs_val = []
accs_train = []

for C_param in C_param_list:
    # train a SVM model
    svm_model = svm.SVC(C_param, decision_function_shape='ovo', class_weight='balanced') # define the model
    svm_model.fit(train_data_scaled, train_labels) # train

    predicted_labels_val = svm_model.predict(val_data_scaled) # predit
    acc = accuracy_score(val_labels, predicted_labels_val)
    print('C_param = ' + str(C_param) + '  accuracy = ' + str(acc))

    if acc > acc_best:
        acc_best = acc
        svm_best = svm_model
        C_opt = C_param

    accs_val.append(acc)
    accs_train.append(accuracy_score(train_labels, svm_model.predict(train_data_scaled)))

print('acc_best on val = ' + str(acc_best))
print('C_opt = ' + str(C_opt))

predicted_labels_test = svm_best.predict(test_data_scaled) # predit
print('test acc = ' + str(accuracy_score(test_labels, predicted_labels_test)))

"""Plot the best C param"""

import matplotlib.pyplot as plt

plt.plot(C_param_list, accs_val, label='validation', color='red', scalex='log')
plt.plot(C_param_list, accs_train, label='train', color='blue', scalex='log')
plt.plot(C_opt, acc_best, 'go')
plt.xscale('log')
plt.legend()
plt.show()

C = np.zeros([4, 4])

for idx, item in enumerate(test_data_scaled):
    label = svm_best.predict([item]) # predit
    C[int(test_labels[idx])][int(label[0])] += 1

print(C)

# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(C, classes=classes.values(), title='Confusion matrix, without normalization')

# Plot normalized confusion matrix
plt.figure()
plot_confusion_matrix(C, classes=classes.values(), normalize=True,
                      title='Normalized confusion matrix')

plt.show()

"""### The regularization parameter and **random search for C param**"""

# train a SVM model
C_param = 1
# or decision_function_shape='ovr'
svm_model = svm.SVC(C_param, decision_function_shape='ovo', class_weight='balanced') # define the model
print(svm_model)

from sklearn.metrics import accuracy_score

svm_model.fit(train_data_scaled, train_labels) # train

predicted_labels_test = svm_model.predict(test_data_scaled) # predit
print(accuracy_score(test_labels, predicted_labels_test))

val_acc = accuracy_score(val_labels, svm_model.predict(val_data_scaled))

C_param_list = np.logspace(0, 3, 10000, endpoint=True, base = 10) - 0.99
a = np.arange(10000)
np.random.shuffle(a)
C_param_list = C_param_list[a[:25]]
C_param_list = np.sort(C_param_list)
print(C_param_list)

svm_best = svm_model
acc_best = val_acc
C_opt = C_param

C_params = []
accs_val = []
accs_train = []

for C_param in C_param_list:
    # train a SVM model
    svm_model = svm.SVC(C_param, decision_function_shape='ovo', class_weight='balanced') # define the model
    svm_model.fit(train_data_scaled, train_labels) # train

    predicted_labels_val = svm_model.predict(val_data_scaled) # predit
    acc = accuracy_score(val_labels, predicted_labels_val)
    print('C_param = ' + str(C_param) + '  accuracy = ' + str(acc))

    if acc > acc_best:
        acc_best = acc
        svm_best = svm_model
        C_opt = C_param

    accs_val.append(acc)
    accs_train.append(accuracy_score(train_labels, svm_model.predict(train_data_scaled)))

print('acc_best on val = ' + str(acc_best))
print('C_opt = ' + str(C_opt))

predicted_labels_test = svm_best.predict(test_data_scaled) # predit
print('test acc = ' + str(accuracy_score(test_labels, predicted_labels_test)))

import matplotlib.pyplot as plt

plt.plot(C_param_list, accs_val, label='validation', color='red', scalex='log')
plt.plot(C_param_list, accs_train, label='train', color='blue', scalex='log')
plt.plot(C_opt, acc_best, 'go')
plt.xscale('log')
plt.legend()
plt.show()

C = np.zeros([4, 4])

for idx, item in enumerate(test_data_scaled):
    label = svm_best.predict([item]) # predit
    C[int(test_labels[idx])][int(label[0])] += 1

print(C)

# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(C, classes=classes.values(), title='Confusion matrix, without normalization')

# Plot normalized confusion matrix
plt.figure()
plot_confusion_matrix(C, classes=classes.values(), normalize=True,
                      title='Normalized confusion matrix')

plt.show()

"""# **Training k-NN**

![knn.jpeg](https://i2.wp.com/blog.kaggle.com/wp-content/uploads/2015/04/04_1nn_map.png)

An example of the difference between Nearest Neighbor and a 5-Nearest Neighbor classifier, using 2-dimensional points and 3 classes (red, blue, green). The colored regions show the decision boundaries induced by the classifier with an L2 distance. The white regions show points that are ambiguously classified (i.e. class votes are tied for at least two classes). Notice that in the case of a NN classifier, outlier datapoints (e.g. green point in the middle of a cloud of blue points) create small islands of likely incorrect predictions, while the 5-NN classifier smooths over these irregularities, likely leading to better generalization on the test data (not shown). Also note that the gray regions in the 5-NN image are caused by ties in the votes among the nearest neighbors (e.g. 2 neighbors are red, next two neighbors are blue, last neighbor is green).

## **Grid search**
"""

from sklearn.neighbors import KNeighborsClassifier

K_param = 3
neigh = KNeighborsClassifier(n_neighbors=K_param, weights='uniform')  # define the model
neigh.fit(train_data_scaled, train_labels) #train

predicted_labels_test = neigh.predict(test_data_scaled) # predit
print(accuracy_score(test_labels, predicted_labels_test))

val_acc = accuracy_score(val_labels, neigh.predict(val_data_scaled))

knn_best = neigh
acc_best = val_acc
K_opt = K_param

K_params = []
accs_val = []
accs_train = []

for K_param in range(1, 25):
    # train a Knn model
    neigh = KNeighborsClassifier(n_neighbors=K_param, weights='uniform')  # define the model
    neigh.fit(train_data_scaled, train_labels) #train

    predicted_labels_val = neigh.predict(val_data_scaled) # predit
    acc = accuracy_score(val_labels, predicted_labels_val)
    print('K_param = ' + str(K_param) + '  accuracy = ' + str(acc))

    if acc > acc_best:
        acc_best = acc
        knn_best = neigh
        K_opt = K_param

    accs_val.append(acc)
    accs_train.append(accuracy_score(train_labels, neigh.predict(train_data_scaled)))

print('acc_best on val = ' + str(acc_best))
print('K_opt = ' + str(K_opt))

predicted_labels_test = knn_best.predict(test_data_scaled) # predit
print('test acc = ' + str(accuracy_score(test_labels, predicted_labels_test)))

import matplotlib.pyplot as plt

plt.plot(range(1, 25), accs_val, label='validation', color='red')
plt.plot(range(1, 25), accs_train, label='train', color='blue')
plt.plot(K_opt, acc_best, 'go')
plt.legend()
plt.show()

C = np.zeros([4, 4])

for idx, item in enumerate(test_data_scaled):
    label = knn_best.predict([item]) # predit
    C[int(test_labels[idx])][int(label[0])] += 1

print(C)

# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(C, classes=classes.values(), title='Confusion matrix, without normalization')

# Plot normalized confusion matrix
plt.figure()
plot_confusion_matrix(C, classes=classes.values(), normalize=True,
                      title='Normalized confusion matrix')

plt.show()

"""# **Training NN**"""

import torch

# using CUDA (GPU) if is possible
CUDA_LAUNCH_BLOCKING=1

plt.ion()  

if torch.cuda.is_available():
    device = torch.device('cuda')
    print("Using CUDA")
else:
    device = torch.device('cpu')
    print("Using CPU")

# transform all fata to tensors and move to GPU
train_data_scaled_tensor = torch.Tensor(train_data_scaled).to(device)
train_labels_tensor = torch.Tensor(train_labels).to(device)
val_data_scaled_tensor = torch.Tensor(val_data_scaled).to(device)
val_labels_tensor = torch.Tensor(val_labels).to(device)
test_data_scaled_tensor = torch.Tensor(test_data_scaled).to(device)
test_labels_tensor = torch.Tensor(test_labels).to(device)

import matplotlib.pyplot as plt

# plot loss function
def plot_loss(loss, label, color='blue'):
    plt.plot(loss, label=label, color=color)
    plt.legend()

"""# **Training**
What follows is pretty standard pytorch code for training.

For every epoch we iterate over all the training set, compute the loss , and adjust the network weights with loss.backward() and optimizer.step(). Then we evaluate the performance over the validaton set. At the end of every epoch we print the network progress (loss and accuracy). The accuracy will tell us how many predictions were correct.

As we said before, transfer learning can work on smaller dataset too, so for every epoch we only iterate over half the trainig dataset (worth noting that it won't exactly be half of it over the entire training, as the data is shuffled, but it will almost certainly be a subset)
"""

import torch.nn as nn
import torch.nn.functional as F

class Net(nn.Module):
    # nn.Module - base class for all models
    # easy acces to .parameters() and .zero_grad()
    # define .forward() instead of __call__()
    
    def __init__(self, in_size, h_size1, h_size2, out_size, p = 0.05):
        super().__init__()
        self._layer1 = nn.Linear(in_size,h_size1).to(device)
        self._layer2 = nn.Linear(h_size1,h_size2).to(device)
        self._layer3 = nn.Linear(h_size2,out_size).to(device)
        self._dropout1 = nn.Dropout(p=p)
        self._dropout2 = nn.Dropout(p=p)
        
    def forward(self, x):
        x = self._dropout1(F.relu(self._layer1(x)).to(device))
        x = self._dropout2(F.relu(self._layer2(x)).to(device))
        x = self._layer3(x).to(device)
        x = F.softmax(x).to(device)
        return x.to(device)
        
    def train(self, train_data, train_labels, 
              epochs=400, lr=0.01, verbose=100, l2_weight=0,
              val_data=None, val_labels=None, plot_val = True):
        #use optimizers to take care of the update step
        optimizer1 = torch.optim.SGD(self.parameters(), lr=lr,
                               weight_decay = l2_weight)
        optimizer2 = torch.optim.Adagrad(self.parameters(), lr=lr,
                               weight_decay = l2_weight)
        optimizer3 = torch.optim.RMSprop(self.parameters(), lr=lr,
                               weight_decay = l2_weight)
        optimizer4 = torch.optim.Adam(self.parameters(), lr=lr,
                               weight_decay = l2_weight)
        
        criterion = nn.CrossEntropyLoss();
        
        train_loss = []
        val_loss = []
        for e in range(epochs):
            optimizer1.zero_grad()   # zero the gradient buffers
            input = train_data
            output = self(train_data)
            loss = criterion(output, train_labels)
            loss.backward()
            optimizer1.step()    # Does the update
            
            train_loss.append(loss.cpu().detach().numpy())
            if verbose!=0 and e%verbose==0:
                print("Loss - train :")
                print(loss)
            if val_data is not None:
                output = self(val_data)
                loss = criterion(output, val_labels)
                if verbose!=0 and e%verbose==0:
                    print("Loss - validation :")
                    print(loss)
                val_loss.append(loss.cpu().detach().numpy())

        if(plot_val):    
            plot_loss(train_loss, 'train-loss')
            if len(val_loss)>0:
                plot_loss(val_loss, 'val-loss', color='red')

    def accuracy(self, data, true_labers):
        num_ok = 0
        for idx, test in enumerate(data):
            output = net(test.type(torch.float))
            target = true_labers[idx]
            if output.max(0)[1] == target:
                num_ok += 1
        return num_ok / len(data)

#define net
net = Net(64, 512, 128, 4)
net.to(device)
print(net)

#train from 2 examples from train set
input = train_data_scaled_tensor[0:2][:]
print(input.shape)
output = net(input.type(torch.float))
print(output.shape)
target = train_labels_tensor[0:2][:]
print(target.shape)

criterion = nn.CrossEntropyLoss()

loss = criterion(output, target.type(torch.long))
print(loss)

#train from all examples from train set
net.train((train_data_scaled_tensor).type(torch.float), (train_labels_tensor).type(torch.long), 
        epochs=10000,lr=0.1,verbose=100,
        val_data = (val_data_scaled_tensor).type(torch.float), 
        val_labels=(val_labels_tensor).type(torch.long))

# evaluate one example from test set
input = test_data_scaled_tensor[0][:]
print(input)
output = net(input.type(torch.float))
print(output)
print(output.max(0)[1])
target = test_labels_tensor[0]
print(target)

# evaluate net from all examples from test set
num_ok = 0
C = np.zeros([4, 4])

for idx, test in enumerate(test_data_scaled_tensor):
    output = net(test.type(torch.float))
    target = test_labels_tensor[idx]
    C[int(test_labels_tensor[idx])][int(output.max(0)[1])] += 1
    if output.max(0)[1] == target:
        num_ok += 1

print('acc = ' + str(num_ok / len(test_data_scaled_tensor)))

print(C)

# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(C, classes=classes.values(), title='Confusion matrix, without normalization')

# Plot normalized confusion matrix
plt.figure()
plot_confusion_matrix(C, classes=classes.values(), normalize=True,
                      title='Normalized confusion matrix')

plt.show()

"""## **Random search for learning rate**"""

lr = np.logspace(-5, 1, 10000, endpoint=True, base = 10)
a = np.arange(10000)
np.random.shuffle(a)
lr_param_list = lr[a[:25]]
lr_param_list = np.sort(lr_param_list)
print(lr_param_list)

nn_best = net
acc_best = net.accuracy(val_data_scaled_tensor, val_labels_tensor)
lr_opt = 0.01

lr_params = []
accs_val = []
accs_train = []

for lr_param in lr_param_list:
    # train a NN model
    net = Net(64, 512, 128, 4)
    net.to(device)

    net.train((train_data_scaled_tensor).type(torch.float), (train_labels_tensor).type(torch.long), 
        epochs=10000,lr=0.1,verbose=100,
        val_data = (val_data_scaled_tensor).type(torch.float), 
        val_labels=(val_labels_tensor).type(torch.long), 
        plot_val = False) 

    acc = net.accuracy(val_data_scaled_tensor, val_labels_tensor)
    print('lr_param = ' + str(lr_param) + '  accuracy = ' + str(acc))

    if acc > acc_best:
        acc_best = acc
        net_best = net
        lr_opt = lr_param

    accs_val.append(acc)
    accs_train.append(net.accuracy(train_data_scaled_tensor, train_labels_tensor))

print('acc_best on val = ' + str(acc_best))
print('lr_opt = ' + str(lr_opt))

print('acc best = ' + str(net_best.accuracy(test_data_scaled_tensor, test_labels_tensor)))

import matplotlib.pyplot as plt

plt.plot(lr_param_list, accs_val, label='validation', color='red')
plt.plot(lr_param_list, accs_train, label='train', color='blue')
plt.plot(lr_opt, acc_best, 'go')
plt.legend()
plt.show()

num_ok = 0
C = np.zeros([4, 4])

for idx, test in enumerate(test_data_scaled_tensor):
    output = net_best(test.type(torch.float))
    target = test_labels_tensor[idx]
    C[int(test_labels_tensor[idx])][int(output.max(0)[1])] += 1
    if output.max(0)[1] == target:
        num_ok += 1

# Plot non-normalized confusion matrix
plt.figure()
plot_confusion_matrix(C, classes=classes.values(), title='Confusion matrix, without normalization')

# Plot normalized confusion matrix
plt.figure()
plot_confusion_matrix(C, classes=classes.values(), normalize=True,
                      title='Normalized confusion matrix')

plt.show()

"""# **Learning only on the first reading of the muscles, not on all 8 readings**"""

#define net
net = Net(8, 512, 128, 4)
net.to(device)
print(net)

train_data_scaled_tensor_first = train_data_scaled_tensor[:, :8]
val_data_scaled_tensor_first = val_data_scaled_tensor[:, :8]
test_data_scaled_tensor_first = test_data_scaled_tensor[:, :8]

#train from all examples from train set
net.train((train_data_scaled_tensor_first).type(torch.float), (train_labels_tensor).type(torch.long), 
        epochs=10000,lr=0.1,verbose=100,
        val_data = (val_data_scaled_tensor_first).type(torch.float), 
        val_labels=(val_labels_tensor).type(torch.long))

print(net.accuracy(test_data_scaled_tensor_first, test_labels_tensor))

# train a SVM model
C_param = 1
# or decision_function_shape='ovr'
svm_model = svm.SVC(C_param, decision_function_shape='ovo', class_weight='balanced') # define the model
print(svm_model)

from sklearn.metrics import accuracy_score

svm_model.fit(train_data_scaled[:, :8], train_labels) # train

predicted_labels_test = svm_model.predict(test_data_scaled[:, :8]) # predit

print(accuracy_score(test_labels, predicted_labels_test))