{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesk.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "haUWbgIqdmDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files, auth, drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VELUX7LyfFR7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount to drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "data_dir_drive ='/content/gdrive/My Drive/Colab Notebooks/NLP1/Lab5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1L_WVClRhZt",
        "colab_type": "code",
        "outputId": "c12c4517-3f48-4098-a88f-553c411e2d3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "! pip install nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1dL4MpiRxEy",
        "colab_type": "code",
        "outputId": "27adea5c-1f09-4177-ebf8-5db5d5c17d58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NLTK Downloader\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> d\n",
            "\n",
            "Download which package (l=list; x=cancel)?\n",
            "  Identifier> wordnet\n",
            "    Downloading package wordnet to /root/nltk_data...\n",
            "      Unzipping corpora/wordnet.zip.\n",
            "\n",
            "---------------------------------------------------------------------------\n",
            "    d) Download   l) List    u) Update   c) Config   h) Help   q) Quit\n",
            "---------------------------------------------------------------------------\n",
            "Downloader> q\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-0ODKMg3tMz",
        "colab_type": "text"
      },
      "source": [
        "# **Lesk**\n",
        "Lesk measure is used to measure the relatedness of two words(senses) by counting the number of words they have in common (overlaps), in their definitions (glosses). The Lesk measure is the number of such common words.\n",
        "\n",
        "Lesk algorithm is used in word disambiguation; it associates a sense to a given word based on how related it is to the context (the rest of the words in the text).\n",
        "\n",
        "Lesk measure is already implemented in nltk:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70h5Ap6D3xg9",
        "colab_type": "code",
        "outputId": "aa55e64b-85bd-4ab9-8096-f339dcb37b44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from nltk.wsd import lesk\n",
        "\n",
        "sys = lesk(nltk.word_tokenize('Students enjoy going to school, studying and reading books'),'school')\n",
        "print(sys)\n",
        "print(sys.definition())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Synset('school.v.01')\n",
            "educate in or as if in a school\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhSEJUv-4GTA",
        "colab_type": "text"
      },
      "source": [
        "**Extended Gloss Overlaps (Extended Lesk)**\n",
        "This technique was presented by Satanjeev Banerjee and Ted Pedersen in 2003 in an [article](https://www.researchgate.net/publication/2563220_Extended_Gloss_Overlaps_as_a_Measure_of_Semantic_Relatedness).\n",
        "\n",
        "The algorithm measures the relatedness of two words. Just like Lesk, it counts the overlaps of glosses, however it takes into account the related glosses of the two word as well.\n",
        "\n",
        "Suppose that we have two synsets s1 and s2. For both of them we obtain the glosses of the synsets for all:\n",
        "\n",
        "hypernyms\n",
        "hyponyms\n",
        "meronyms\n",
        "holonyms\n",
        "troponyms\n",
        "attributes\n",
        "similar–to\n",
        "also–see\n",
        "In computing the score, for each single word that appears in both glosses we add 1. However if it appears in a common phrase, supposing the length of common phrase is L, we add L2(for example, if \"white bread\" appears in both glosses, we add 4). We obviusly don't add the score for the separate words in the phrase. We try to find the longest common phrase (tht doesn't start or end with a pronoun, preposition, article or conjunction in both glosses.\n",
        "\n",
        "If we have multiple synsets in the same relation to one of the given synsets we create a string with all the glosses concatenated."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LgNvhZx4H_I",
        "colab_type": "text"
      },
      "source": [
        "# **Exercises and homework**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PJW_AiW4Nw_",
        "colab_type": "text"
      },
      "source": [
        "# **1**\n",
        "Implement Original Lesk algorithm with the help of a function that computes the score for two given glosses. For a given text and a given word, try to find the sense of that word, considering the Lesk measure. Check your result with the already implemented (simplified) lesk algorithm in nltk. You may have different results, as the simplified Lesk algorithm compares the target word glosses with the words from the context (not their definitions)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMIvN91T4KgE",
        "colab_type": "code",
        "outputId": "a43507eb-fcec-4292-8e5d-6a47d2be675f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import numpy as np\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "def compare_glosses(gloss1, gloss2):\n",
        "    words1 = word_tokenize(gloss1)\n",
        "    words2 = word_tokenize(gloss2)\n",
        "\n",
        "    words1 = [x.lower() for x in words1 if x.isalnum()]\n",
        "    words2 = [x.lower() for x in words2 if x.isalnum()]\n",
        "\n",
        "    #print(gloss1, gloss2)\n",
        "    #print(words1, words2)\n",
        "\n",
        "    ps=nltk.PorterStemmer()\n",
        "\n",
        "    stem1 = list(map(lambda x: ps.stem(x), words1))\n",
        "    stem2 = list(map(lambda x: ps.stem(x), words2))\n",
        "\n",
        "    #print(stem1, stem2)\n",
        "\n",
        "    r = 0;\n",
        "    for s1 in stem1:\n",
        "        for s2 in stem2:\n",
        "            if s1 == s2:\n",
        "                r += 1\n",
        "\n",
        "    return r\n",
        "\n",
        "c1 = compare_glosses(wordnet.synsets('school')[0].definition(), wordnet.synsets('school')[1].definition())\n",
        "c2 = compare_glosses(wordnet.synsets('school')[1].definition(), wordnet.synsets('school')[3].definition())\n",
        "c3 = compare_glosses(wordnet.synsets('school')[0].definition(), wordnet.synsets('cat')[0].definition())\n",
        "\n",
        "print(c1, c2, c3)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 2 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwbuwCIuo1sV",
        "colab_type": "code",
        "outputId": "7f0fa980-0f5f-4026-d508-cc2b7775b549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "def myLesk(context, word):\n",
        "    synsets = wordnet.synsets(word)\n",
        "\n",
        "    maximum = 0\n",
        "    syn = None\n",
        "\n",
        "    for s in synsets:\n",
        "        m = 0\n",
        "        for word_context in context:\n",
        "            for word_sense in wordnet.synsets(word_context):\n",
        "                m += compare_glosses(s.definition(), word_sense.definition())\n",
        "        print(m, s.definition())\n",
        "        if m > maximum:\n",
        "            maximum = m\n",
        "            syn = s\n",
        "    return syn\n",
        "\n",
        "sys = myLesk(nltk.word_tokenize('Students enjoy going to school, studying and reading books'),'school')\n",
        "print(sys)\n",
        "print(sys.definition())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16 an educational institution\n",
            "76 a building where young people receive education\n",
            "161 the process of being formally educated at a school\n",
            "348 a body of creative artists or writers or thinkers linked by a similar style or by similar teachers\n",
            "227 the period of instruction in a school; the time period when school is in session\n",
            "31 an educational institution's faculty and students\n",
            "109 a large group of fish\n",
            "190 educate in or as if in a school\n",
            "169 teach or refine to be discriminative in taste or judgment\n",
            "193 swim in or form a large group of fish\n",
            "Synset('school.n.04')\n",
            "a body of creative artists or writers or thinkers linked by a similar style or by similar teachers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VlcsXWXvmi_",
        "colab_type": "code",
        "outputId": "9b2b07a8-5c2c-47a2-fc51-48ea5982bf7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "sys = myLesk(nltk.word_tokenize('The reactor explosion killed two of the reactor operating staff.'),'nuclear')\n",
        "print(sys)\n",
        "print(sys.definition())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49 (weapons) deriving destructive energy from the release of atomic energy\n",
            "110 of or relating to or constituting the nucleus of an atom\n",
            "126 of or relating to or constituting the nucleus of a cell\n",
            "38 constituting or like a nucleus\n",
            "Synset('nuclear.a.03')\n",
            "of or relating to or constituting the nucleus of a cell\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAnQ5BDb4RLV",
        "colab_type": "text"
      },
      "source": [
        "# **2**\n",
        "Implement extended Lesk algorithm. For a list of 7-10 words, print the measure for each pair of words (without repeating the words). Just like in the former exercise, try to obtain the word sense for the given text and word. Can you find a text and word where simple Lesk gives the wrong answer, however extended Lesk gives the right answer?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBV4ocWs4R0s",
        "colab_type": "code",
        "outputId": "54e1e3c1-e8f6-4cf7-84fd-0eedce48ad33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def compare_glosses_overlap(gloss1, gloss2):\n",
        "    words1 = word_tokenize(gloss1)\n",
        "    words2 = word_tokenize(gloss2)\n",
        "\n",
        "    words1 = [x.lower() for x in words1 if x.isalnum()]\n",
        "    words2 = [x.lower() for x in words2 if x.isalnum()]\n",
        "\n",
        "    #print(gloss1, gloss2)\n",
        "    #print(words1, words2)\n",
        "\n",
        "    ps=nltk.PorterStemmer()\n",
        "\n",
        "    stem1 = list(map(lambda x: ps.stem(x), words1))\n",
        "    stem2 = list(map(lambda x: ps.stem(x), words2))\n",
        "\n",
        "    if len(stem1) > len(stem2):\n",
        "        stem1, stem2 = stem2, stem1\n",
        "\n",
        "    #print(stem1, stem2)\n",
        "\n",
        "    r = 0;\n",
        "    for size in range(len(stem1))[::-1]: #revese order\n",
        "        for i in range(len(stem1)):\n",
        "            if i + size == len(stem1):\n",
        "                break\n",
        "            patch1 = stem1[i:i + size + 1]\n",
        "            for j in range(len(stem2) - size):\n",
        "                patch2 = stem2[j:j + size + 1]\n",
        "                if patch1 == patch2:\n",
        "                    r += len(patch1) ** 2\n",
        "                    stem1 = stem1[:i] + stem1[i + size + 1:] #cut what I found\n",
        "                    stem2 = stem2[:j] + stem2[j + size + 1:]\n",
        "\n",
        "    return r\n",
        "\n",
        "c1 = compare_glosses_overlap('w1 w2 w3 w4 w5 w6 w7 w8', 'w10 w1 w2 w11 w5 w6 w7 w12 w8')\n",
        "c2 = compare_glosses_overlap(wordnet.synsets('school')[0].definition(), wordnet.synsets('school')[1].definition())\n",
        "c3 = compare_glosses_overlap(wordnet.synsets('school')[1].definition(), wordnet.synsets('school')[3].definition())\n",
        "c4 = compare_glosses_overlap(wordnet.synsets('school')[0].definition(), wordnet.synsets('cat')[0].definition())\n",
        "\n",
        "print(c1, c2, c3, c4)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14 1 2 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj3GZcOJ_zBF",
        "colab_type": "code",
        "outputId": "376001f4-1821-479a-df54-80bc9cb1f0ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "def compute_extended_sense(syn):\n",
        "    hypernyms = syn.hypernyms()\n",
        "    hyponyms = syn.hyponyms()\n",
        "    holonyms = syn.substance_holonyms() + syn.part_holonyms() + syn.part_holonyms()\n",
        "    meronyms = syn.substance_meronyms() + syn.part_meronyms() + syn.part_meronyms()\n",
        "    troponyms = syn.entailments()\n",
        "    attributes = syn.attributes()\n",
        "    similar_to = syn.similar_tos()\n",
        "    also_see = syn.also_sees()\n",
        "\n",
        "    hypernym_s = '' #concatenate deffinitions\n",
        "    for hypernym in hypernyms:\n",
        "        hypernym_s += hypernym.definition()\n",
        "    hyponym_s = ''\n",
        "    for hyponym in hyponyms:\n",
        "        hyponym_s += hyponym.definition()\n",
        "    holonym_s = ''\n",
        "    for holonym in holonyms:\n",
        "        holonym_s += holonym.definition()\n",
        "    meronym_s = ''\n",
        "    for meronym in meronyms:\n",
        "        meronym_s += meronym.definition()\n",
        "    troponym_s = ''\n",
        "    for troponym in troponyms:\n",
        "        troponym_s += troponym.definition()\n",
        "    attribute_s = ''\n",
        "    for attribute in attributes:\n",
        "        attribute_s += attribute.definition()\n",
        "    similar_to_s = ''\n",
        "    for e in similar_to:\n",
        "        similar_to_s += e.definition()\n",
        "    also_see_s = ''\n",
        "    for e in also_see:\n",
        "        also_see_s += e.definition()\n",
        "\n",
        "    return [syn.definition(),\n",
        "            hypernym_s,\n",
        "            hyponym_s,\n",
        "            holonym_s,\n",
        "            meronym_s,\n",
        "            troponym_s,\n",
        "            attribute_s,\n",
        "            similar_to_s,\n",
        "            also_see_s]\n",
        "\n",
        "compute_extended_sense(wordnet.synset('water.n.01'))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['binary compound that occurs at room temperature as a clear colorless odorless tasteless liquid; freezes into ice below 0 degrees centigrade and boils above 100 degrees centigrade; widely used as a solvent',\n",
              " 'chemical compound composed of only two elementsfluid matter having no fixed shape but a fixed volume',\n",
              " 'water used for a bathwater accumulated in the bilge of a shipwater in which dishes and cooking utensils are washedwater that has been purified by distillationwater that is not saltyunderground water that is held in the soil and in pervious rockswater that contains mineral salts (as calcium and magnesium ions) that limit the formation of lather with soapwater that has been blessed by a priest for use in symbolic purificationsolution of calcium hydroxide in water used as an antacidmelted snow or icewater containing saltspartially melted snowwater that is not hard (does not contain mineral salts that interfere with the formation of lather with soap)water directly from the spigotthe water present in hydrated compounds',\n",
              " \"the part of the earth's surface covered with water (such as a river or lake or ocean)water frozen in the solid statesmall crystals of icesalty fluid secreted by sweat glandsa crystal of snowa drop of the clear salty saline solution secreted by the lacrimal glands\",\n",
              " \"a nonmetallic univalent element that is normally a colorless and odorless highly flammable diatomic gas; the simplest and lightest and most abundant element in the universea nonmetallic bivalent element that is normally a colorless odorless tasteless nonflammable diatomic gas; constitutes 21 percent of the atmosphere by volume; the most abundant element in the earth's crust\",\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXSAoz-t_Ig-",
        "colab_type": "code",
        "outputId": "c894234f-2d52-4f27-96b0-2b2234275323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "def myExtendedLesk(context, word):\n",
        "    synsets = wordnet.synsets(word)\n",
        "\n",
        "    maximum = 0\n",
        "    syn = None\n",
        "\n",
        "    for s in synsets:\n",
        "        m = 0\n",
        "        L = compute_extended_sense(s)\n",
        "        for word_context in context:\n",
        "            for word_sense in wordnet.synsets(word_context):\n",
        "                L_word_sense = compute_extended_sense(word_sense)\n",
        "                for l in L: # cartesian product\n",
        "                    for l_w in L_word_sense:\n",
        "                        m += compare_glosses_overlap(l, l_w)\n",
        "        print(m, s.definition())\n",
        "        if m > maximum:\n",
        "            maximum = m\n",
        "            syn = s\n",
        "    return syn\n",
        "\n",
        "sys = myExtendedLesk(nltk.word_tokenize('Students enjoy going to school, studying and reading books'),'school')\n",
        "print(sys)\n",
        "print(sys.definition())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66926 an educational institution\n",
            "4257 a building where young people receive education\n",
            "1085 the process of being formally educated at a school\n",
            "26395 a body of creative artists or writers or thinkers linked by a similar style or by similar teachers\n",
            "2776 the period of instruction in a school; the time period when school is in session\n",
            "369 an educational institution's faculty and students\n",
            "974 a large group of fish\n",
            "1569 educate in or as if in a school\n",
            "1254 teach or refine to be discriminative in taste or judgment\n",
            "783 swim in or form a large group of fish\n",
            "Synset('school.n.01')\n",
            "an educational institution\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwOTycdgnYUw",
        "colab_type": "code",
        "outputId": "cd180961-a67b-4186-8a5e-b5a3cb6950e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "sys = myLesk(nltk.word_tokenize('The reactor explosion killed two of the reactor operating staff.'),'nuclear')\n",
        "print(sys)\n",
        "print(sys.definition())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "49 (weapons) deriving destructive energy from the release of atomic energy\n",
            "110 of or relating to or constituting the nucleus of an atom\n",
            "126 of or relating to or constituting the nucleus of a cell\n",
            "38 constituting or like a nucleus\n",
            "Synset('nuclear.a.03')\n",
            "of or relating to or constituting the nucleus of a cell\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGC8xHGGnYTH",
        "colab_type": "code",
        "outputId": "77a4d545-b350-440a-b555-50eb45cbe0fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "sys = myExtendedLesk(nltk.word_tokenize('The reactor explosion killed two of the reactor operating staff.'),'nuclear')\n",
        "print(sys)\n",
        "print(sys.definition())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "207 (weapons) deriving destructive energy from the release of atomic energy\n",
            "272 of or relating to or constituting the nucleus of an atom\n",
            "369 of or relating to or constituting the nucleus of a cell\n",
            "444 constituting or like a nucleus\n",
            "Synset('nuclear.s.04')\n",
            "constituting or like a nucleus\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwCgRco4nuDB",
        "colab_type": "code",
        "outputId": "e08a3312-7e87-4790-d6c0-9e9fce6fbef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "sys = lesk(nltk.word_tokenize('The reactor explosion killed two of the reactor operating staff.'),'nuclear')\n",
        "print(sys)\n",
        "print(sys.definition())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Synset('nuclear.a.03')\n",
            "of or relating to or constituting the nucleus of a cell\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}