# -*- coding: utf-8 -*-
"""left_corner_parser.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gVI7mO07vlXeJHTPXU6RMpbPRhdnEwl_
"""

from google.colab import files, auth, drive

# Mount to drive
drive.mount('/content/gdrive', force_remount=True)
data_dir_drive ='/content/gdrive/My Drive/Colab Notebooks/NLP1/Lab3'

! pip install nltk

import nltk
import numpy as np

nltk.download()

from nltk import CFG, Nonterminal
grammar1 = nltk.CFG.fromstring("""  S -> NP VP | TO VB
                                    VP -> V NP | V NP PP | V S | V PP
                                    PP -> P NP  
                                    V -> "caught" | "ate" | "likes" | "like" | "chase" | "go"
                                    NP -> Det N | Det N PP | PRP
                                    Det -> "the" | "a" | "an" | "my" | "some"
                                    N -> "mice" | "cat" | "dog" |  "school"
                                    P -> "in" | "to" | "on"
                                    TO -> "to"
                                    PRP -> "I"  """)

sent=["I", "like", "my", "dog"]
rdp = nltk.RecursiveDescentParser(grammar1)
for tree in rdp.parse(sent):
    print(tree)

nltk.app.rdparser()

srp = nltk.ShiftReduceParser(grammar1)
sent=["I", "like", "my", "dog"]
for tree in srp.parse(sent):
    print(tree)

nltk.app.srparser()

"""# **Left corner parser**
The Left-Corner Parser uses also a top-down strategy. A left-corner parser does some preprocessing before the parsing itself. It creates an association between each non-terminal label and a list of all possible left corners (start of the expression). Before applying a production from the context free grammar, it searches for the next word that there is one starting label (in the left corners list) that applies to it. (http://cs.union.edu/~striegnk/courses/nlp-with-prolog/html/node53.html?fbclid=IwAR1957LMxy1A9OTm2gpzZFzrpzo97BzRWFMKXSHOdzZoAC1NEyOdmD3hEJ4)
"""

grammar2 = nltk.CFG.fromstring("""  S -> NP VP
                                    NP -> Det N | PN 
                                    VP -> IV | vincent
                                    Det -> the
                                    N -> robber
                                    PN -> vincent
                                    IV -> died  """)

string = 'vincent died'
grammar2.productions()

start = grammar2.start()
print(start)

nltk.help.upenn_tagset('S')

def recognize(grammar, N):
    return grammar.productions(lhs=N)

def find_productions_by_left_corners(grammar, N):
    return grammar.productions(rhs=N) # start with N e.g. ... -> N...

def get_left_corner(production):
    return production.rhs()[0]

from collections import deque

def Bottom_up_Parsing(word, top, grammar):
    r = [] #result
    q = deque() 
    start_productions = find_productions_by_left_corners(grammar, word) # add production where word is left corner
    start_productions += find_productions_by_left_corners(grammar, Nonterminal(word))
    #print(start_productions)
    if len(start_productions) == 0:
        return False
    else:
        res = []
        for production in start_productions:
            q.append(production)
            if production.lhs() == top:
                res.append([production]) # i have match
        if len(res):
            return res

    while len(q) != 0: # i have productions
        curr_production = q[0] # get first production
        q.popleft() 
        #print(curr_production)

        productions = find_productions_by_left_corners(grammar, curr_production.lhs()) # add new production where current start symbol is left-corner
        #print(productions)
        #print()
        r.append((curr_production, len(productions))) # add current production in result

        while r[-1][1] == 0: #clean result list
            r.pop(-1)
            if len(r):
                r[-1] = (r[-1][0], r[-1][1]-1) 
            else:
                break

        for production in productions:
            if production.lhs() == top:
                r.append((production, None))
                f = []
                for elem in r:
                    f.append(elem[0])
                    
                res.append(f)
                r = r[:1]
            q.appendleft(production)
    
    if res == []:
        return False
    else:
        return res

Bottom_up_Parsing('am', Nonterminal('VP'), grammar3)

grammar1.productions()

x = Bottom_up_Parsing('to', Nonterminal('S'), grammar1)
print(x)

x = Bottom_up_Parsing('robber', Nonterminal('N'), grammar2)
print(x)

def left_corner_parser(grammar, string):

    words = string.split()
    flag = grammar.start() #top-down
    index = 0

    def left_corner_parser_aux(grammar = grammar, index = index, flag = flag):
        #print(index, flag)
        rest = 0
        productions = Bottom_up_Parsing(words[index], flag, grammar)

        if productions == False:
            return False
        else:
            #print(productions[:][::-1])
            pass
        returnValue = True
        for productionList in productions:
            for production in productionList[1:]:
                if len(production.rhs()) == 1:
                    continue # I'm ok, there is no need for top-down
                else: # need top-down step
                    for symbol in production.rhs()[1:]:
                        index += 1
                        if index >= len(words): #case for insufficient words
                            returnValue = False
                            break
                        rest = left_corner_parser_aux(grammar, index, symbol)
                        if not rest:
                            returnValue = False
                            #print(index, symbol, production)
                            break
                        else:
                            returnValue = True
            index -= 1
            if returnValue:
                print(productionList)
                break
        #print(index, flag, returnValue)
        return returnValue

    val = left_corner_parser_aux()
    return val

val = left_corner_parser(grammar2, 'the robber died')
print(val)

val = left_corner_parser(grammar1, 'I like my dog')
print(val)

grammar3 = nltk.CFG.fromstring("""  S -> NP VP
                                    S -> VP
                                    NP -> DT NN
                                    NP -> DT JJ NN
                                    NP -> PRP
                                    VP -> VBP NP
                                    VP -> VBP VP
                                    VP -> VBG NP
                                    VP -> TO VP
                                    VP -> VB
                                    VP -> VB NP
                                    NN -> "show" | "book"
                                    PRP -> "I"
                                    VBP -> "am"
                                    VBG -> "watching"
                                    VB -> "show"
                                    DT -> "a" | "the"
                                    MD -> "will"  """)

grammar3.productions()

x = Bottom_up_Parsing('am', Nonterminal('VP'), grammar3)
print(x)

val = left_corner_parser(grammar3, 'I am watching a show')
print(val)