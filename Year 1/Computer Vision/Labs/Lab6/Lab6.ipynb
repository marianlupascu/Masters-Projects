{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computer Vision\n",
    "### Lab 6\n",
    "#### Project 2  - Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template matching for detecting the snooker balls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the templates balls\n",
    "templates = []\n",
    "base_folder_matching = 'template_matching'\n",
    "images_names = glob.glob(os.path.join(base_folder_matching, \"*.jpg\")) \n",
    "for image_name in images_names:      \n",
    "    template = cv.imread(image_name) \n",
    "    templates.append(template) \n",
    "    cv.imshow(\"template\", template)\n",
    "    cv.waitKey(2000)\n",
    "    cv.destroyAllWindows()\n",
    "    \n",
    "color_dict = {0: \"black\",\n",
    "              1: \"blue\",\n",
    "              2: \"brown\",\n",
    "              3: \"green\",\n",
    "              4: \"pink\",\n",
    "              5: \"red\",\n",
    "              6: \"white\",\n",
    "              7: \"yellow\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AssertionError",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-cf62a0db70c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# read the first frame from a video\n",
    "video_path = os.path.join('videos_table', \"3_table.mp4\")\n",
    "\n",
    "cap = cv.VideoCapture(video_path)\n",
    "assert cap.isOpened() is True\n",
    "\n",
    "ret, first_frame = cap.read()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'first_frame' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-cc8230655c3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# run template matching using a threshold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfirst_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtemplate\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemplates\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'first_frame' is not defined"
     ]
    }
   ],
   "source": [
    "# run template matching using a threshold\n",
    "frame = first_frame.copy() \n",
    "idx = -1\n",
    "for template in templates:    \n",
    "    idx = idx + 1\n",
    "    template_gray = cv.cvtColor(template, cv.COLOR_BGR2GRAY)    \n",
    "    w, h = template_gray.shape[::-1]\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    res = cv.matchTemplate(frame_gray, template_gray, cv.TM_CCOEFF_NORMED)\n",
    "    \n",
    "    cv.imshow(\"Map\", res)\n",
    "    threshold = 0.75\n",
    "    loc = np.where( res >= threshold)\n",
    "    frame_draw = first_frame.copy() \n",
    "    for pt in zip(*loc[::-1]):\n",
    "        cv.rectangle(frame_draw, pt, (pt[0] + w, pt[1] + h), (0,0,255), 1)\n",
    "        \n",
    "    print(color_dict[idx])\n",
    "    cv.imshow(\"Template_matching \" + color_dict[idx], frame_draw)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run template matching using different methods and min/max value\n",
    "frame = first_frame.copy()\n",
    "\n",
    "# All the 6 methods for comparison in a list\n",
    "methods = ['cv.TM_SQDIFF', 'cv.TM_SQDIFF_NORMED','cv.TM_CCORR',\n",
    "            'cv.TM_CCORR_NORMED', 'cv.TM_CCOEFF', 'cv.TM_CCOEFF_NORMED' ]\n",
    "\n",
    "# methods = ['cv.TM_CCOEFF_NORMED']\n",
    "\n",
    "idx = -1\n",
    "for template in templates:                \n",
    "    idx = idx + 1\n",
    "    template_gray = cv.cvtColor(template, cv.COLOR_BGR2GRAY)    \n",
    "    w, h = template_gray.shape[::-1]\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "       \n",
    "    for meth in methods:        \n",
    "        method = eval(meth)\n",
    "        frame = first_frame.copy()\n",
    "        \n",
    "        # apply template Matching\n",
    "        res = cv.matchTemplate(frame_gray, template_gray,method)\n",
    "         \n",
    "        min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "\n",
    "        # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "        if method in [cv.TM_SQDIFF, cv.TM_SQDIFF_NORMED]:\n",
    "            top_left = min_loc                      \n",
    "        else:\n",
    "            top_left = max_loc\n",
    "            \n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "\n",
    "        cv.rectangle(frame,top_left, bottom_right, 255, 2)\n",
    "        \n",
    "        cv.imshow(\"Template_matching \" + color_dict[idx] +' ' + meth, frame)\n",
    "        cv.waitKey(0)  \n",
    "        cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histrogram of colors for detecting the snooker balls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a method to compute the histogram of a window in the quantized BGR color space\n",
    "def compute_hist(img, bins_0, bins_1 ,bins_2):\n",
    "    histogram = np.zeros((bins_0, bins_1, bins_2))\n",
    "    \n",
    "    bin_len_0 = 256 / bins_0\n",
    "    bin_len_1 = 256 / bins_1\n",
    "    bin_len_2 = 256 / bins_2\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            int_0 = int(img[i][j][0] // bin_len_0)\n",
    "            int_1 = int(img[i][j][1] // bin_len_1)\n",
    "            int_2 = int(img[i][j][2] // bin_len_2)\n",
    "            histogram[int_0, int_1, int_2] += 1\n",
    "\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'first_frame' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2cb2045a89dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Select ROI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfirst_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mx_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_min\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselectROI\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mx_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_min\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_min\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'first_frame' is not defined"
     ]
    }
   ],
   "source": [
    "# Select ROI\n",
    "frame = first_frame.copy()\n",
    "x_min, y_min, w, h = cv.selectROI(frame)\n",
    "x_max = x_min + w\n",
    "y_max = y_min + h\n",
    "\n",
    "# Crop image\n",
    "img_crop = frame[y_min:y_max, x_min:x_max]\n",
    "\n",
    "# Display cropped image \n",
    "cv.imshow(\"Image\", img_crop)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 48.   0.   0.   0.]\n",
      "  [113.  44.   0.   0.]\n",
      "  [214.  43.   4.   0.]\n",
      "  [  1.   3.   0.   0.]]\n",
      "\n",
      " [[  0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.]\n",
      "  [  0.   2.  29.   0.]\n",
      "  [  0.   7.  46.  15.]]\n",
      "\n",
      " [[  0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.]\n",
      "  [  0.   0.  20. 161.]]\n",
      "\n",
      " [[  0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.]]]\n",
      "750.0\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "# compute the color histogram of the window in the quantized BGR color space\n",
    "#u se our function\n",
    "histogram_img = compute_hist(img_crop, 4, 4, 4)\n",
    "print(histogram_img)\n",
    "print(histogram_img.sum())\n",
    "print(img_crop.shape[0] * img_crop.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 48.   0.   0.   0.]\n",
      "  [113.  44.   0.   0.]\n",
      "  [214.  43.   4.   0.]\n",
      "  [  1.   3.   0.   0.]]\n",
      "\n",
      " [[  0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.]\n",
      "  [  0.   2.  29.   0.]\n",
      "  [  0.   7.  46.  15.]]\n",
      "\n",
      " [[  0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.]\n",
      "  [  0.   0.  20. 161.]]\n",
      "\n",
      " [[  0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.]\n",
      "  [  0.   0.   0.   0.]]]\n"
     ]
    }
   ],
   "source": [
    "# compute the color histogram of the window in the quantized BGR color space\n",
    "# use the function provided by OpenCV\n",
    "hist_img = cv.calcHist([img_crop], [0, 1, 2], None, [4, 4, 4], [0, 256, 0, 256, 0, 256]) \n",
    "print(hist_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, we are going to compute the histograms for our templates\n",
    "hist_templates = []\n",
    "for template in templates:\n",
    "    template_hist = cv.calcHist([template], [0, 1, 2], None, [4, 4, 4], [0, 256, 0, 256, 0, 256])\n",
    "    hist_templates.append(template_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7085474175329844, 2.514432310880351, 1.7402492048217768, 2.148930095975731, 1.0032398584401512, 2.2277004624634142, 0.27557843509747354, 1.6342202754606932]\n",
      "white\n"
     ]
    }
   ],
   "source": [
    "# do normalization for each histogram\n",
    "distances = []\n",
    "for i in range(len(templates)):\n",
    "    hist_img_norm = hist_img / (hist_img.sum())\n",
    "    hist_template_norm = hist_templates[i] / (hist_templates[i].sum())    \n",
    "    # use one of the possible distances between histograms - see function cv.compareHist\n",
    "    dist = cv.compareHist(hist_img_norm, hist_template_norm, cv.HISTCMP_CHISQR_ALT)\n",
    "    distances.append(dist)\n",
    "print(distances)\n",
    "print(color_dict[np.argmin(distances)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracking\n",
    "# change the path to match on your machine\n",
    "base_folder = 'videos'\n",
    "path_video1 = os.path.join(base_folder, \"3.mp4\")\n",
    "path_video2 = os.path.join(base_folder, \"3_annotated.mp4\")\n",
    "\n",
    "#sanity check - run the video\n",
    "cap = cv.VideoCapture(path_video2)  \n",
    "current_frame = 0\n",
    "max_number_of_frame_to_run = 750\n",
    "\n",
    "while(cap.isOpened()): \n",
    "    ret, frame = cap.read() # Read the frame\n",
    "    if ret is True: \n",
    "        current_frame = current_frame + 1 \n",
    "        \n",
    "        cv.imshow(\"Frame\",frame)\n",
    "        \n",
    "        if current_frame > max_number_of_frame_to_run:\n",
    "            break\n",
    "            \n",
    "        if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# after playing the video, release the video capture    \n",
    "cap.release()\n",
    "# close all the frames\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ground-truth file\n",
    "black_ball_gt = np.loadtxt(os.path.join(base_folder, 'video_3_black.txt'))\n",
    "white_ball_gt = np.loadtxt(os.path.join(base_folder, 'video_3_white.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([196.,  -1.,  -1.,  -1.,  -1.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the first line contains the lenght (number of frames) of the video (followed by -1 in order to keep the dimension of the array)\n",
    "black_ball_gt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0., 592.,  52., 614.,  71.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the other lines contains the frame index and the coordinates of the bounding box\n",
    "black_ball_gt[1]\n",
    "# frame_idx, x_min, y_min, x_max, y_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_ball_using_hist_of_colors(video_path):\n",
    "    \n",
    "    bboxes = []\n",
    "    \n",
    "    cap = cv.VideoCapture(video_path)\n",
    "    ret, first_frame = cap.read() # Read the first frame \n",
    "    \n",
    "    x, y, w, h = cv.selectROI(first_frame) \n",
    "    track_window = (x, y, w, h)\n",
    "    \n",
    "    roi = first_frame[y: y + h, x: x + w]\n",
    "    annotated_frame = cv.rectangle(first_frame, (x, y), (x+w,y+h), 255, 2)\n",
    " \n",
    "    cv.imshow('First frame initialization', annotated_frame)\n",
    "    cv.waitKey(10000)\n",
    "    \n",
    "    \n",
    "    roi_hist = cv.calcHist([roi], [0 ,1, 2], None, [4, 4, 4], [0, 256, 0, 256, 0, 256]) \n",
    "    roi_hist_norm = roi_hist / roi_hist.sum()\n",
    "\n",
    "    roi_gray = cv.cvtColor(roi, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    frame_idx = 0\n",
    "    while cap.isOpened():\n",
    "        frame_idx += 1\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret is True: \n",
    "            frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "            mask1 = np.int8(np.zeros(frame_gray.shape))\n",
    "            center = (y + h//2, x + h//2)\n",
    "\n",
    "            y_min = np.max((0, center[0] - (2*h)))\n",
    "            y_max = np.min((frame.shape[0], center[0] + (2*h)))\n",
    "            x_min = np.max((0, center[1] - (2*w)))\n",
    "            x_max = np.min((frame.shape[1], center[1] + (2*w)))\n",
    "            \n",
    "            mask1[y_min: y_max, x_min: x_max] = 255\n",
    "\n",
    "            frame_gray_mask = cv.bitwise_and(frame_gray,frame_gray,mask=mask1)\n",
    "            cv.imshow('frame gray mask', frame_gray_mask)\n",
    "            cv.waitKey(500)\n",
    "\n",
    "            res = cv.matchTemplate(frame_gray_mask, roi_gray, cv.TM_CCOEFF_NORMED)        \n",
    "            min_val, max_val, min_loc, max_loc = cv.minMaxLoc(res)\n",
    "\n",
    "            y = max_loc[1]\n",
    "            x = max_loc[0]\n",
    "            bboxes.append([frame_idx, x, y, x + w, y + h])\n",
    "            img2 = cv.rectangle(frame, (x, y), (x + w, y + h), 255, 2)\n",
    "            cv.imshow('img2', img2)\n",
    "\n",
    "            if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "                \n",
    "        else:\n",
    "            break\n",
    "    # after playing the video, release the video capture    \n",
    "    cap.release()\n",
    "    # close all the frames\n",
    "    cv.destroyAllWindows()\n",
    "    return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = \"3_table.mp4\"\n",
    "bboxes = track_ball_using_hist_of_colors(os.path.join(\"videos_table\", video_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the intersection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    # return the intersection over union value\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_percentage_tracking(gt_bboxes, predicted_bboxes, num_frames):\n",
    "    num_frames = int(num_frames)\n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    \n",
    "    gt_dict = {}\n",
    "    for gt_box in gt_bboxes:\n",
    "        gt_dict[gt_box[0]] = gt_box[1:]\n",
    "    \n",
    "    pred_dict = {}\n",
    "    for pred_bbox in predicted_bboxes:\n",
    "        pred_dict[pred_bbox[0]] = pred_bbox[1:]\n",
    "        \n",
    "    for i in range(num_frames):\n",
    "        if gt_dict.get(i, None) is None and pred_dict.get(i, None) is None: # the ball is not on the table\n",
    "            tp += 1 \n",
    "        \n",
    "        elif gt_dict.get(i, None) is not None and pred_dict.get(i, None) is None: # the ball is not detected\n",
    "            fp += 1\n",
    "            \n",
    "        elif gt_dict.get(i, None) is None and pred_dict.get(i, None) is not None: # the ball is not on the table, but it is 'detected'\n",
    "            fp += 1\n",
    "            \n",
    "        elif gt_dict.get(i, None) is not None and pred_dict.get(i, None) is not None: # the ball is on the table and it is detected\n",
    "            \n",
    "            iou = bb_intersection_over_union(gt_dict[i], pred_dict[i])\n",
    "            if iou >= 0.2:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1 \n",
    "             \n",
    "            \n",
    "    print(tp, fp)\n",
    "    assert tp + fp == num_frames\n",
    "    perc = tp / (tp + fp)\n",
    "    \n",
    "    return perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9693877551020408"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_percentage_tracking(white_ball_gt[1:], bboxes, white_ball_gt[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}