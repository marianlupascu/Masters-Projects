# -*- coding: utf-8 -*-
"""Fake_News_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1InQQwNi-IAahAjv5kc3UKGj5byTOfTm2

## Imports and data preparation
"""

from google.colab import drive
drive.mount('/content/gdrive')

import pandas as pd
import numpy as np

FOLDER = "gdrive/My Drive/NLP/Fake_News"
dataset = pd.read_csv(FOLDER + "/train.csv")

# Display the dataset
print(dataset.columns)
news = dataset['text'].apply(str)
labels = np.array(dataset['label'])

print(news)

"""Preprocessing the reviews"""

import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import PorterStemmer
nltk.download('punkt')

def preprocess_data(news):
  news = news.str.lower() # Lowercasing

  # Stopwords removal
  #nltk.download('stopwords')
  #stop_words = stopwords.words('english')

  #news = news.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)])) # Remove stopwords

  # Stemming
  #stemmer = PorterStemmer()

  #news = news.apply(lambda x: [stemmer.stem(y) for y in word_tokenize(x) if y.isalpha()])

  #print(news)

  #news = [' '.join(str(x) for x in article) for article in news]

  print(news)

  return news

news = preprocess_data(news)

"""## Encoding"""

from sklearn.model_selection import train_test_split

def split_dataset(text, labels):
  X_train, X_test, Y_train, Y_test = train_test_split(text, labels, test_size = 0.1)
  return X_train, Y_train, X_test, Y_test

X, Y, X_test, Y_test = split_dataset(news, labels)

"""### Tfidf"""

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(min_df = 5,
                             max_df = 0.8,
                             sublinear_tf = True,
                             use_idf = True)

X = vectorizer.fit_transform(X)
X_test = vectorizer.transform(X_test)

"""### Bag of words"""

from sklearn.feature_extraction.text import CountVectorizer
count_vect = CountVectorizer()

X = count_vect.fit_transform(X)
X_test = count_vect.transform(X_test)

"""## Models

### Classical approaches

#### SVM
"""

from sklearn import svm

classifier = svm.SVC(kernel = 'linear')
classifier.fit(X, Y)

"""Get accuracy on the test dataset"""

from sklearn.metrics import accuracy_score

prediction = classifier.predict(X_test)
print(accuracy_score(Y_test, prediction))

"""TFIDF:

With stop words removal -> 0.9783653846153846

Without stop words removal -> 0.9697115384615385

Stemming without stopwords removal -> 0.9591346153846154

Stemming with stopwords removal -> 0.9552884615384616

BOW:

With stopwords removal -> 0.9442307692307692

Without stopwords removal -> 0.9552884615384616

Stemming without stopwords removal -> 0.9298076923076923

Stemming with stopwords removal -> 0.9278846153846154

#### NB
"""

from sklearn.naive_bayes import MultinomialNB
classifier = MultinomialNB().fit(X, Y)

from sklearn.metrics import accuracy_score

prediction = classifier.predict(X_test)
print(accuracy_score(Y_test, prediction))

"""TFIDF:

With stop words removal -> 0.9038461538461539

Without stop words removal -> 0.9115384615384615

Stemming without stopwords removal -> 0.8971153846153846

Stemming with stopwords removal -> 0.8836538461538461

BOW:

With stopwords removal -> 0.8990384615384616

Without stopwords removal -> 0.9149038461538461

Stemming without stopwords removal -> 0.8682692307692308

Stemming with stopwords removal -> 0.8778846153846154

#### Logistic Regression
"""

from sklearn.linear_model import LogisticRegression
LR = LogisticRegression()
LR.fit(X, Y)

print(LR.score(X_test, Y_test))

"""TFIDF:

With stop words removal -> 0.9634615384615385

Without stop words removal -> 0.9533653846153847

Stemming without stopwords removal -> 0.9418269230769231

Stemming with stopwords removal -> 0.948076923076923

BOW:

With stopwords removal -> 0.9615384615384616

Without stopwords removal -> 0.9644230769230769

Stemming without stopwords removal -> 0.9394230769230769

Stemming with stopwords removal -> 0.94375

### Deep learning

#### BERT
"""

X_train, Y_train, X_validation, Y_validation = split_dataset(X, Y)

!pip install transformers

import torch
# We will run the model on the GPU

device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(device)

from transformers import BertTokenizer

# Load the BERT tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case = False)

train_input_ids = []
train_attention_masks = []

for news in X_train:

    encoded_dict = tokenizer.encode_plus(
                        news,
                        add_special_tokens = True, # Add [CLS] and [SEP]
                        max_length = 128,          # Pad and truncate to 128 characters
                        pad_to_max_length = True,
                        return_attention_mask = True,   # Create attention masks so that BERT knows not to look at padding tokens
                        return_tensors = 'pt',     # Return pytorch tensors
                   )
    
    # Add the encoded value to the list
    train_input_ids.append(encoded_dict['input_ids'])
    
    # And the attention mask
    train_attention_masks.append(encoded_dict['attention_mask'])

# Convert the lists into tensors
train_input_ids = torch.cat(train_input_ids, dim = 0)
train_attention_masks = torch.cat(train_attention_masks, dim = 0)
train_labels = torch.tensor(Y_train)

validation_input_ids = []
validation_attention_masks = []

for news in X_validation:

    encoded_dict = tokenizer.encode_plus(
                        news,
                        add_special_tokens = True, # Add [CLS] and [SEP]
                        max_length = 128,          # Pad and truncate to 128 characters
                        pad_to_max_length = True,
                        return_attention_mask = True,   # Create attention masks so that BERT knows not to look at padding tokens
                        return_tensors = 'pt',     # Return pytorch tensors
                   )
    
    # Add the encoded value to the list
    validation_input_ids.append(encoded_dict['input_ids'])
    
    # And the attention mask
    validation_attention_masks.append(encoded_dict['attention_mask'])

# Convert the lists into tensors
validation_input_ids = torch.cat(validation_input_ids, dim = 0)
validation_attention_masks = torch.cat(validation_attention_masks, dim = 0)
validation_labels = torch.tensor(Y_validation)

test_input_ids = []
test_attention_masks = []

for news in X_test:

    encoded_dict = tokenizer.encode_plus(
                        news,
                        add_special_tokens = True, # Add [CLS] and [SEP]
                        max_length = 128,          # Pad and truncate to 128 characters
                        pad_to_max_length = True,
                        return_attention_mask = True,   # Create attention masks so that BERT knows not to look at padding tokens
                        return_tensors = 'pt',     # Return pytorch tensors
                   )
    
    # Add the encoded value to the list
    test_input_ids.append(encoded_dict['input_ids'])
    
    # And the attention mask
    test_attention_masks.append(encoded_dict['attention_mask'])

# Convert the lists into tensors
test_input_ids = torch.cat(test_input_ids, dim = 0)
test_attention_masks = torch.cat(test_attention_masks, dim = 0)
test_labels = torch.tensor(Y_test)

from torch.utils.data import TensorDataset

# Create a tensor dataset out of the ids, attention masks and labels
train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)
validation_dataset = TensorDataset(validation_input_ids, validation_attention_masks, validation_labels)
test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)

from torch.utils.data import DataLoader, RandomSampler, SequentialSampler

batch_size = 32

# Create dataloaders for the training, validation and testing sets
train_dataloader = DataLoader(
            train_dataset,
            sampler = RandomSampler(train_dataset), # Select batches randomly
            batch_size = batch_size
        )

validation_dataloader = DataLoader(
            validation_dataset,
            sampler = SequentialSampler(validation_dataset), # The order does not matter here, so we can just read them sequentially
            batch_size = batch_size
        )
test_dataloader = DataLoader(
            test_dataset,
            sampler = SequentialSampler(test_dataset), # The order does not matter here, so we can just read them sequentially
            batch_size = batch_size
        )

from transformers import BertForSequenceClassification, AdamW
 
model = BertForSequenceClassification.from_pretrained(
    "bert-base-multilingual-cased",
    output_attentions = False, # Ww do not need the attention weights
    output_hidden_states = False, # We do not need to see the hidden states
)
 
# Run the model on the GPU
model.cuda()

optimizer = AdamW(model.parameters(),
                  lr = 2e-5, # Learning rate
                  eps = 1e-8 # Epsilon
                )

from transformers import get_linear_schedule_with_warmup
 
epochs = 5
 
# The number of training steps is [number of batches] x [number of epochs] 
total_steps = len(train_dataloader) * epochs
 
# Use a learning rate scheduler so that we can optimize the training
scheduler = get_linear_schedule_with_warmup(optimizer, 
                                            num_warmup_steps = 0,
                                            num_training_steps = total_steps)

# Calculate the accuracy of our prediction vs the ground truth
def get_accuracy(pred, labels):
    pred_flat = np.argmax(pred, axis = 1).flatten()
    labels_flat = labels.flatten()
    return np.sum(pred_flat == labels_flat) / len(labels_flat)

import numpy as np
 
training_stats = []
 
for epoch in range(0, epochs):
    
    # Training
 
    print("")
    print('Epoch {:} / {:}'.format(epoch + 1, epochs))
    print('Training...')
 
    total_train_loss = 0
    model.train()
 
    for step, batch in enumerate(train_dataloader):
 
        # Progress update
        if step % 40 == 0 and not step == 0:
            # Report progress.
            print('  Batch {:>5,}  of  {:>5,}'.format(step, len(train_dataloader)))
 
        # Copy each tensor to the GPU
        batch_input_ids = batch[0].to(device)
        batch_input_mask = batch[1].to(device)
        batch_labels = batch[2].to(device)
 
        # Clear any previously calculated gradients
        model.zero_grad()        
 
        output = model(batch_input_ids, attention_mask = batch_input_mask, labels = batch_labels)
        loss = output.loss
        
        # We will calculate the total training loss at the end
        total_train_loss += loss.item()
 
        # Calculate the gradients with a backward pass
        loss.backward()
 
        # Clip the norm of the gradients to 1.0 so that we can prevent the "exploding gradients" problem
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
 
        # Update parameters and take a step using the computed gradient
        optimizer.step()
 
        # Update the learning rate
        scheduler.step()
 
    # Average training loss over all of the batches
    avg_train_loss = total_train_loss / len(train_dataloader)            
 
    print("")
    print("  Average training loss: {0:.4f}".format(avg_train_loss))
        
    # Validation
 
    print("")
    print("Validation...")
 
    model.eval()
 
    total_valid_accuracy = 0
    total_valid_loss = 0
 
    for batch in validation_dataloader:
        
        # Copy each tensor to the GPU
        batch_input_ids = batch[0].to(device)
        batch_input_mask = batch[1].to(device)
        batch_labels = batch[2].to(device)
        
        with torch.no_grad():
            output = model(batch_input_ids, attention_mask = batch_input_mask, labels = batch_labels)
            loss = output.loss
            logits = output.logits # Model values before activation
            
        # We will calculate the total validation loss at the end
        total_valid_loss += loss.item()
 
        # Move logits and labels to CPU
        logits = logits.detach().cpu().numpy()
        labels = batch_labels.to('cpu').numpy()
 
        total_valid_accuracy += get_accuracy(logits, labels)
        
 
    # Report the final accuracy for this validation run.
    avg_val_accuracy = total_valid_accuracy / len(validation_dataloader)
    print("  Accuracy: {0:.4f}".format(avg_val_accuracy))
 
    # Calculate the average validation loss over all of the batches
    avg_val_loss = total_valid_loss / len(validation_dataloader)
    
    print("  Validation Loss: {0:.4f}".format(avg_val_loss))
 
    # Record all statistics from this epoch
    training_stats.append(
        {
            'epoch': epoch,
            'Training Loss': avg_train_loss,
            'Validation Loss': avg_val_loss,
            'Validation Accuracy.': avg_val_accuracy,
        }
    )

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
 
# Create a DataFrame from our training stats
df = pd.DataFrame(data = training_stats)
 
 
sns.set(style = 'darkgrid')
sns.set(font_scale = 1.5)
plt.rcParams["figure.figsize"] = (12, 6)
 
# Plot the training and validation losses
plt.plot(df['Training Loss'], 'b-o', label = "Training")
plt.plot(df['Validation Loss'], 'g-o', label = "Validation")
 
plt.title("Training and Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
 
plt.show()

model.eval()
 
predictions, ground_truth = [], []
 
total_test_accuracy = 0
 
for batch in test_dataloader:
  # Add batch to GPU
  batch = tuple(i.to(device) for i in batch)
  
  # Get the inputs from the dataloader
  batch_input_ids, batch_input_mask, batch_labels = batch
  
  with torch.no_grad():
      outputs = model(batch_input_ids, attention_mask = batch_input_mask)
 
  logits = outputs.logits
 
  # Move logits and labels to CPU
  logits = logits.detach().cpu().numpy()
  labels = batch_labels.to('cpu').numpy()
 
  total_test_accuracy += get_accuracy(logits, labels)
  
  predictions.extend(np.argmax(logits, axis=1).flatten())
  ground_truth.extend(labels.flatten())
 
# Report the final accuracy for the test set
avg_test_accuracy = total_test_accuracy / len(test_dataloader)
print("Accuracy: {0:.4f}".format(avg_test_accuracy))